<!DOCTYPE html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.w3.org/2002/06/xhtml2/ http://www.w3.org/MarkUp/SCHEMA/xhtml2.xsd" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<link href="Styles/Style00.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style01.css" rel="stylesheet" type="text/css" />

<style type="text/css">body{margin:1em;background-color:transparent!important;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}#sbo-rt-content *{word-wrap:break-word!important;word-break:break-word!important;}#sbo-rt-content table,#sbo-rt-content pre{overflow-x:unset!important;overflow:unset!important;overflow-y:unset!important;white-space:pre-wrap!important;}</style></head>
<body><div id="sbo-rt-content"><section epub:type="chapter" role="doc-chapter" aria-labelledby="c03_1">&#13;
<header>&#13;
<h1 id="c03_1"><span epub:type="pagebreak" id="Page_63" role="doc-pagebreak" aria-label="63"/><span id="c03"/><span class="chapterNumber">Chapter 3</span><br/><span class="chapterTitle">Integrated Information Risk Management</span></h1>&#13;
</header>&#13;
<aside>&#13;
<div class="top hr"><hr/></div>&#13;
<section class="feature3"><span id="c03-fea-0001"/>&#13;
<h3 id="head-2-33">THE SSCP EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE:</h3>&#13;
<ul class="none" id="c03-list-0001">&#13;
<li id="c03-li-0001"><b>Domain 1: Security Operations and Administration</b>&#13;
<ul class="tick" id="c03-list-0002">&#13;
<li id="c03-li-0002"><b>1.5: Participate in asset management lifecycle</b></li>&#13;
</ul>&#13;
</li>&#13;
<li id="c03-li-0003"><b>Domain 3: Risk Identification, Monitoring, and Analysis</b>&#13;
<ul class="tick" id="c03-list-1002">&#13;
<li id="c03-li-0004"><b>3.1: Understand the risk management process</b></li>&#13;
<li id="c03-li-0005"><b>3.2 Understand legal and regulatory concerns</b></li>&#13;
</ul>&#13;
</li>&#13;
</ul>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
<section aria-label="chapter opening"><span id="c03-sec-0001"/>&#13;
<p id="c03-para-0003"><span epub:type="pagebreak" id="Page_64" role="doc-pagebreak" aria-label="64"/>Defense is a set of strategies, management is about making decisions, and mitigation is a set of tactics chosen to implement those decisions. <i>Integrated information risk management</i> is about protecting what’s important to the organization. It’s about what to protect and why; risk mitigation addresses how. Some outcomes, processes, or assets are by their nature much more critical to organizational success (and survival!) than others. By the same token, some threats pose more danger to the organization and its vulnerabilities than others do. The CIANA+PS set of cybersecurity needs prevails, and the SSCP can fill many important roles in shaping an effective integrated information defense strategy, as you’ll see in this chapter. We’ll also borrow from NIST Special Publication 800-37 Rev. 2, Information Systems Security and Privacy Risk Management Framework (RMF), to look at what leadership and management have to do to start the risk management process.</p>&#13;
<p id="c03-para-0004">We are also going to challenge your thinking about defense—specifically about an idea called <i>defense in depth</i>. Some cybersecurity systems vendors claim that defense in depth is “dead,” whereas many others in the industry continue to strongly recommend it. You’ll see that the difference between whether defense in depth is very much alive and well, or on its way to the scrap heap, can be found in one word: <i>integrated</i>. Let’s see what this means.</p>&#13;
</section>&#13;
<section aria-labelledby="head-2-34"><span id="c03-sec-0002"/>&#13;
<h2 id="head-2-34">It’s a Dangerous World</h2>&#13;
<p id="c03-para-0005">Let’s face it: your organization’s systems, its information, its very existence is in danger. Your money, your capital equipment, supplies, and inventory all are at risk of theft or damage. Your information assets are at risk of being stolen, and your trade secrets, customer information, and business practices, even your talented people, are “up for grabs” if hackers can get into your files. Perhaps most important, your organization’s <i>reputation</i> for honesty, reliability, and quality could be ruined by hostile action by such <i>threat actors</i> as these, or just by your own failure to quickly and prudently deal with accidental or natural disruptions to your business activities.</p>&#13;
<p>The key to risk and risk management is simple: <i>it’s about making decisions in reliable ways</i> and using the CIANA+PS to help you know when the decision you’re about to make is a reliable one…and when it is a blind leap into the dark. From the SSCP’s perspective, information security is necessary because it enables more decisions to be made on time and on target. Reliable decision making is as much about long-range planning as it is about incident response. This means that you can rely on the following:</p>&#13;
<ul class="square" id="c03-list-0003">&#13;
<li id="c03-li-0006">Your individual and organizational memory (the information and knowledge you think you already have, know, and understand)</li>&#13;
<li id="c03-li-0007"><span epub:type="pagebreak" id="Page_65" role="doc-pagebreak" aria-label="65"/>New information that you’ve gathered, processed, and used as inputs to this decision</li>&#13;
<li id="c03-li-0008">Your ability to deliberate, examine, review, think, and then to decide, free from disruption</li>&#13;
<li id="c03-li-0009">Your ability to communicate our decision (the “new marching orders”) to those elements of your organization and systems that have to carry them out</li>&#13;
</ul>&#13;
<p id="c03-para-0007">Each element of that basic decision cycle must be <i>reliable</i> if you want to count on your decisions being the right decisions at the right time. Each of those elements has its own CIANA+PS set of needs. By controlling or managing information risk, the SSCP helps the organization manage its decision risk, and thereby manage its overall exposure to risk while it decides and acts to achieve its goals and objectives.</p>&#13;
<p id="c03-para-0008">The good news is that neither the SSCP nor the organizational leaders and stakeholders she works for have to figure out how to do all of this from scratch. Universities, businesses, and governments have for generations been compiling “lessons learned” about organizational management and leadership, especially on topics such as risk management. The dawn of the computer age highlighted the need to bring even more talent and expertise to bear, to find even better ways to manage and mitigate information risk and decisions risk. Since the 1990s, governments, private business, and academia have been collaborating to develop what organizations large and small need to be able to deal with information systems risk. They’ve produced risk management frameworks as well as highly technical standards, practices, and recommendations for the nitty-gritty work of hardening your information systems and defending them in prudent and effective ways.</p>&#13;
<p id="c03-para-0009">A <i>risk management framework</i> is a management tool kit that you can use to bring these kinds of risks (and others) under control. One such framework, published by the U.S. Department of Commerce, National Institute of Standards and Technology, provides what it calls “a systems life cycle approach for security and policy.” We’ll use its overall approach to introduce the concepts of risk, defensive strategies, and responses; then we’ll look more closely at how organizations manage risk and attain some control over it.</p>&#13;
<p>But first, let’s look at what we mean by <i>risk</i> and, more specifically, <i>information risk</i>.</p>&#13;
<aside>&#13;
<div class="top hr"><hr/></div>&#13;
<section class="feature3">&#13;
<p><img alt="Note" src="Images/note.png" class="left" width="76" height="53"/></p>&#13;
<p id="c03-para-0011">Almost all risk management frameworks, standards, and textbooks present these ideas as a top-down, end-to-end process. This does not mean that organizations cannot respond to risks as and when they discover them.</p>&#13;
<p id="c03-para-0012">If you’re working with an organization that does not have a cybersecurity risk management process in place, don’t wait until there’s enough time, money, and management attention available to do a thorough job of it. <i>Start with the first</i>, <i>most obvious risk</i> that you see. Characterize it, assess it, get decisions made about it, and manage it. Then do the next one.</p>&#13;
<p id="c03-para-0013">Over the long run, this may not be efficient. It’s an incremental approach to understanding and improving one’s security posture. As in most things, some action taken to make daily improvements is better than doing nothing at all. It just may mean your organization survives into that longer run.</p>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
<section><span id="c03-sec-0004"/>&#13;
<h3 id="head-3-24"><span epub:type="pagebreak" id="Page_66" role="doc-pagebreak" aria-label="66"/>What Is Risk?</h3>&#13;
<p id="c03-para-0014">Let’s start by giving a formal definition of what we mean by risk. A <i>risk</i> is the possibility that an event can occur that can disrupt or damage the organization’s planned activities, assets, or processes, which may impact the organization’s ability to achieve some or all of its goals and objectives. Risks are further classed as either threats or hazards, based on whether the action is taken by a human (or human organization) with intent, or happens because of accident, acts of nature, or system failures due to wear and tear. Separating risk this way, into threats caused by threat actors and hazards, aligns our thinking about information systems risk with standard business and insurance terminology. Note that <i>risk</i> management still must embrace both threats and hazards, of course.</p>&#13;
<p id="c03-para-0015">Let’s take our definition apart, piece by piece, and see how we can <i>operationalize</i> it—turn it into something we can make part of day-to-day, task-level operational steps we must accomplish to achieve it. We’ll do that from the inside out, as shown in <a href="#c03-fig-0001" id="R_c03-fig-0001">Figure 3.1</a>.</p>&#13;
<figure> <img alt="Schematic illustration of Vulnerability leads to failure, which leads to impact" src="Images/c03f001.png" class="center" width="1433" height="1071"/>&#13;
<figcaption>&#13;
<p><span class="figureLabel"><a href="#R_c03-fig-0001" id="c03-fig-0001" role="doc-backlink">FIGURE 3.1</a></span>   Vulnerability leads to failure, which leads to impact</p>&#13;
</figcaption>&#13;
</figure>&#13;
<p id="c03-para-0016">Start by recognizing that vulnerabilities exist in everything we do, in everything we build—even in each of us. A bulletproof vest cannot stop heavy machine gun fire; structure fires can melt “fireproof” document safes, or even be so hot that safe actually burns. Parts <span epub:type="pagebreak" id="Page_67" role="doc-pagebreak" aria-label="67"/>wear out; mechanisms overheat; anything that runs on electricity can (and will) have that electrical supply fail. Humans make errors as we design, build, and use these systems. And to add insult to injury, the physical world is a <i>noisy</i> place—data gets corrupted, messages get garbled, and the result is often that what we thought we said is not what others think we meant.</p>&#13;
<p id="c03-para-0017">Fortunately, each of these weaknesses is not occurring on a nonstop basis. Risks are “if something happens.” We talk about a vulnerability becoming an event when something goes wrong—when a part fails, when a message doesn’t get through, when a person makes a mistake, or when somebody exploits that vulnerability to cause an unwanted or poorly anticipated event to actually occur. Vulnerabilities by themselves do not cause harmful or disruptive events; it is only when some action is taken (or a required action is not taken) that such an event occurs. Even then, not all events that occur are events of interest to information security professionals. Two events in 2017 illustrate this difference. (We’ll examine more recent events, in greater detail, in <a href="c12.xhtml">Chapter 12</a>, “Cross-Domain Challenges.”)</p>&#13;
<p id="c03-para-0018">Our first example is one of a classical “non-zero day” exploit gone horribly viral in scale. On September 7, 2017, Equifax announced that millions of individual consumer credit report files might have been subject to an “unauthorized disclosure” due to a breach in the security of the company’s systems. Since this initial announcement, continued reporting shows that more than 148 million consumers worldwide might have had their credit history, government identification, and other private data stolen from Equifax by the attackers. In the weeks that followed Equifax’s announcement, an all-too-familiar sequence of events was revealed.</p>&#13;
<p id="c03-para-0019">First, an exploitable software vulnerability was detected in the Apache Struts web software, used by Equifax and many others, by a security researcher in Shanghai, China; he reported his discovery immediately to the Apache Software Foundation, which then published the vulnerability and a fix on March 6, 2017. One day later, the vulnerability showed up in Metasploit, one of the most popular exploitation tool suites used by black hat and white hat hackers alike. By March 10, reconnaissance probes by hackers started to hit the Equifax servers. By early May, attackers exploited these vulnerabilities to gain access to multiple database applications served by many Equifax web pages, and then systematically “exfiltrated” (that is, <i>stole</i>) data from Equifax. Data from a U.S. Government Accountability Office (GAO) report indicates that hackers ran nearly 9,000 unauthorized queries over 76 days, many of which simply blended in with “normal” activity levels, and used standard encryption protocols to further disguise this traffic.</p>&#13;
<p id="c03-para-0020">Equifax detected these exfiltrations on July 30, waited a day to verify that these were in fact unauthorized accesses leading to a data breach, and then shut down the affected servers. Equifax waited until September 7 to report the data losses to the U.S. Federal Trade Commission and to the public, claiming it had no legal obligation to report sooner.</p>&#13;
<p id="c03-para-0021">What were the outcomes of the Equifax data breach? Equifax did spend, by some reports, up to $200 million on improving its systems security measures, and its board of directors did ask the chief executive officer and chief information security officer to retire early—with up to $500 million in retirement and severance benefits intact. As of March 2018, actual claims by consumers totaled $275 million; these are expected to rise to at least $600 million before all claims have been fully resolved.</p>&#13;
<aside>&#13;
<div class="top hr"><hr/></div>&#13;
<section class="feature3" aria-labelledby="head-2-35"><span id="c03-fea-0002"/>&#13;
<h3 id="head-2-35"><span epub:type="pagebreak" id="Page_68" role="doc-pagebreak" aria-label="68"/>Zero Day Exploits</h3>&#13;
<section><span id="c03-sec-0005"/>&#13;
<p>We can look at the lifecycle of an exploitable vulnerability in terms of key events in its life:</p>&#13;
<ul class="square" id="c03-list-0004">&#13;
<li id="c03-li-0010">First discovery</li>&#13;
<li id="c03-li-0011">Notification to the builder or vendor about the vulnerability</li>&#13;
<li id="c03-li-0012">Public notification and reporting of the vulnerability, such as in common vulnerabilities and exploits (CVE) databases</li>&#13;
<li id="c03-li-0013">First release by the builder or vendor of a fix (to correct it) or a patch (to provide a workaround to avoid it)</li>&#13;
<li id="c03-li-0014">Widespread adoption of the fix or patch throughout the marketplace</li>&#13;
</ul>&#13;
<p id="c03-para-0023">Throughout that lifecycle, attackers exploiting that vulnerability have varying degrees of surprise and success.</p>&#13;
<p id="c03-para-0024">A <i>zero day exploit</i> is an exploitation of a newly discovered vulnerability before that vulnerability is discovered by or reported to the developers, vendors, or users of the affected system. The term suggests that the system’s defenders have zero time to prepare for such an exploit, since they are not aware of the vulnerability or the potential for an attack based on it.</p>&#13;
<p id="c03-para-0025">In the Equifax case, for example, there seem to have been at most a few days between discovery of the Apache Struts exploitable errors by a Chinese researcher and his reporting to Apache Software Foundation. From the day he reported it on, exploits using that vulnerability were no longer “zero day.”</p>&#13;
<p id="c03-para-0026">Regrettably, we lack such colorful names as “zero day” for exploits once they’ve taken on a degree of notoriety and thus have lost the element of surprise.</p>&#13;
</section>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
<p id="c03-para-0027">By contrast, consider numerous data systems failures that have caused significant losses to the companies involved. Delta Airlines, for example, had to cancel hundreds of flights in January 2017 due to multiple systems crashes at its Atlanta, Georgia, operations center; this was after its datacenter crashed the previous August when its (supposedly) uninterruptible electrical power systems failed. This cost Delta more than $150 million and inconvenienced tens of thousands of travelers. Yet, by all reports, this event was not of interest to IT security professionals; it was simply a cascading set of errors leading to otherwise preventable failures.</p>&#13;
<p>Not all risks are information security risks, even if they impact the availability of information systems to support decision making. In retrospect, we see that choosing whether an event is a security concern or not is largely a judgment call we may have to make. Two important questions must be asked about such failures or risk occurrences as incidents:</p>&#13;
<ul class="square" id="c03-list-0005">&#13;
<li id="c03-li-0015">First, how predictable are incidents like these? How often do the sorts of mistakes that lead to such incidents happen? When might they happen? If we can predict how often <span epub:type="pagebreak" id="Page_69" role="doc-pagebreak" aria-label="69"/>such circumstances might occur, or identify conditions that increase the likelihood of such mistakes or failures, we might gain insight into ways to prevent them. In risk management terms, this asks us to make reasonable assumptions that help us estimate the <i>frequencies of occurrence</i> and <i>probabilities of occurrence</i> for such events.</li>&#13;
<li id="c03-li-0016">Second, how much impact do they have on the organization, its goals and objectives, and its assets, people, or reputation? What did this <i>cost</i> us, in terms of money, lost business, real damages, injuries or deaths, and loss of goodwill among our customers and suppliers?</li>&#13;
</ul>&#13;
<p id="c03-para-0029">These answers suggest that if something we do, use, or depend on <i>can fail</i>, no matter what the cause, then we can start to look at the <i>how</i> of those failures—but we let those frequencies, probabilities, and possible impacts guide us to prioritize which risks we look at first, and which we can choose to look at later.</p>&#13;
</section>&#13;
<section><span id="c03-sec-0006"/>&#13;
<h3 id="head-3-25">Risk: When Surprise Becomes Disruption</h3>&#13;
<p>We care about risks because when they occur (when they become an incident), they disrupt our plans. Incidents disrupt us in two ways:</p>&#13;
<ul class="square" id="c03-list-0006">&#13;
<li id="c03-li-0017">They break our chain of thought. They interrupt the flow of decision making that we “normally” would be using to carry out our planned, regular, normal activities.</li>&#13;
<li id="c03-li-0018">They cause us to react to their occurrence. We divert time, labor, money, effort, and decision making into responding to that incident.</li>&#13;
</ul>&#13;
<p id="c03-para-0031">Consider, for example, a simple daily set of activities like driving to work. As you back your car out of the driveway, a sudden noise and an impact suggests that you’ve run over something (hopefully not someone!). You stop the car, get out, and look; you find a child’s bicycle had been left in the driveway behind your car. The damage to bicycle and car is minor but not zero; money, time, and effort are required to fix them. You’ve got to decide when and how to get those repairs done, in ways that don’t completely disrupt your plans for the day. And you’re probably both upset (why didn’t you look better first?) and relieved (no one got hurt).</p>&#13;
<p id="c03-para-0032">Most of the time, we think of risks as “bad news.” Things break; opportunities are lost; systems or property is damaged; people get hurt or killed. If we stop and think about this, we see that risk can be good news but still disruptive to our plans. An unexpected opportunity appears (a surprising offer of a dream job, halfway across the country), but to take advantage of it, you must divert resources to do what’s necessary. From an information security perspective, however, you are best off thinking of risk as a negative impact only.</p>&#13;
<p id="c03-para-0033">The occurrence of a risk, therefore, takes our preplanned, previously evaluated, deliberated decisions and action plans and tosses them aside. And it does this because either new information (the bicycle behind your car, the new job) was not <i>anticipated</i> as you put your original decisions together, or your decision process was not set up to deal with that new information without derailing your train of thought.</p>&#13;
<span epub:type="pagebreak" id="Page_70" role="doc-pagebreak" aria-label="70"/>&#13;
<aside>&#13;
<div class="top hr"><hr/></div>&#13;
<section class="feature3"><span id="c03-fea-0003"/>&#13;
<p><img alt="Realworld" src="Images/realworld.png" class="left" width="239" height="36"/></p>&#13;
<h3 id="head-2-36">Case Study: Voter Registration</h3>&#13;
<section><span id="c03-sec-0007"/>&#13;
<p id="c03-para-0034">Throughout this chapter, we’ll look at the information processing needs of modern democracies as a recurring theme. We’ll see that some of the information risks that voting systems face are clearly linked to the information technologies they use, whereas many other risks are linked to choices about information management and operation of those systems.</p>&#13;
<p>We’ll start with a case study on voter registration processes. Many countries use voting systems to empower their citizens to choose elected representatives or other officials and to express opinion about issues. Voter registration systems provide ways to identify lawful, authorized voters by associating <i>personally identifying information</i> (PII) with location information, thus registering a specific person as eligible to vote at a particular local polling place. The process typically works:</p>&#13;
<ol class="decimal" id="c03-list-0007">&#13;
<li id="c03-li-0019">The voter establishes a lawful residence within a voting district.</li>&#13;
<li id="c03-li-0020">The voter registers with the election authority by providing proof of identification (the PII) and proof of residency within the district.</li>&#13;
<li id="c03-li-0021">The election authority validates the PII, verifies the address information, and then adds the voter to the election rolls (the database of registered voters).</li>&#13;
</ol>&#13;
<p id="c03-para-0036">When it’s time for an election, the election authority provides each polling place with a validated list of those registered voters eligible to vote. The polling place officials use this list to ensure that only registered voters vote and that each registered voter votes only one time in only one polling place during that election.</p>&#13;
<p>How does CIANA+PS apply to this process? In most voting processes:</p>&#13;
<ul class="square" id="c03-list-0008">&#13;
<li id="c03-li-0022">Confidentiality is required by law; voters cast their votes anonymously, protecting their freedom to make their own choices without coercion or pressure from the government or from anyone else.</li>&#13;
<li id="c03-li-0023">Integrity of voter registration data is required to ensure that vote fraud does not occur (that is, that only registered voters actually vote, and that no one who was ineligible to be a registered voter was allowed to register).</li>&#13;
<li id="c03-li-0024">Availability of the voter registration system affects each step in the registration and balloting processes. This means that at any time during the process, failures or errors in that system must not deny any voter the opportunity to register. Once registered, the use of registration systems and information during the election must not deny any registered voter the opportunity to actually cast their ballot.</li>&#13;
<li id="c03-li-0025">Nonrepudiation as an outcome results from officials being able to verify the claimed identity of the voter at registration and at voting time; recordkeeping systems also authenticate which officials take what actions throughout the process.</li>&#13;
<li id="c03-li-0026"><span epub:type="pagebreak" id="Page_71" role="doc-pagebreak" aria-label="71"/>Authenticity is reflected in identity proofing during registration and at voting.</li>&#13;
<li id="c03-li-0027">Safety for all concerned requires that name and address information (such as PII) be restricted and not generally available to the public.</li>&#13;
<li id="c03-li-0028">Privacy of voter PII and the actual ballot a voter casts is controlled but not absolute, in most voting systems. Many systems allow for individuals or organizations to audit voter registration records, for example. Secrecy of each ballot is generally preserved by anonymizing or masking the PII associated with the voter who cast that ballot.</li>&#13;
</ul>&#13;
<p id="c03-para-0038">Disruption to an election can occur if failures in the voter registration systems prevent citizens from registering to vote or prevent registered voters from actually being able to vote on Election Day. If either of these risks becomes an incident, the general public or significant subgroups of voters can lose faith and confidence not only in the results of this one election, but also in the electoral process as a whole. This can (and has!) led to civil unrest, demonstrations, and revolutions.</p>&#13;
<p id="c03-para-0039">All because a nation could not keep track of who was eligible to vote…</p>&#13;
</section>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
</section>&#13;
<section><span id="c03-sec-0008"/>&#13;
<h3 id="head-3-26">Information Security: Delivering Decision Assurance</h3>&#13;
<p id="c03-para-0040">Everything people and human organizations do is a series of steps, and each step is a series of substeps; our lives and our businesses run on layers upon layers of tasks and subtasks. You go to work in the morning, but that in itself requires steps (like waking up), and all of those steps contain or are made up of substeps. Businesses get things done in step-by-step ways; these <i>business processes</i> are often chained together, the results of one process becoming the inputs to the next. Within each process we often find many subprocesses, as well as many decision points that affect the way each particular process is applied to each particular set of input conditions, day in and day out. This is why sometimes we say that all work is actually <i>decision work</i>, since even the simplest task you do requires you to decide “Should I do this next?” before starting; “Am I doing this right?” while you’re doing it; and “Did I finish it correctly?” when you think it’s time to stop.</p>&#13;
<p id="c03-para-0041">Each step in a process is a decision. That’s the number one most powerful lesson of <i>cybernetics</i>, the study of control systems. The most powerful lesson from 10,000 years of warfare and conflict between nations is that first, you defeat the way your adversary <i>thinks</i>. By defeating his strategy, you may not even need to engage his armies on the field—or you will spend far less effort in actual combat if you must nonetheless! By outthinking your opponent in this way, you are much more able to win through to your own goals, often at much lower costs to you. We call this <i>getting inside the opponent’s decision cycle</i>. And for the same 10,000 years, this same lesson has shaped the way marketplaces work and thus shapes the way that businesses compete with one another.</p>&#13;
<p>Every one of those decisions, large or small, is an opportunity for somebody or something to “mess with” what you had planned and what you want and need to accomplish:</p>&#13;
<ul class="square" id="c03-list-0009">&#13;
<li id="c03-li-0029">Competitors can learn what you’re planning to do.</li>&#13;
<li id="c03-li-0030">Customer requests can be mishandled, misrouted, or ignored, which may lead to customers taking their business elsewhere.</li>&#13;
<li id="c03-li-0031">Costs can be erroneously increased, and revenues can be lost.</li>&#13;
</ul>&#13;
<aside>&#13;
<div class="top hr"><hr/></div>&#13;
<section class="feature3" aria-labelledby="head-2-37"><span id="c03-fea-0004"/>&#13;
<h3 id="head-2-37"><span epub:type="pagebreak" id="Page_72" role="doc-pagebreak" aria-label="72"/>Booking an Airline Flight</h3>&#13;
<section><span id="c03-sec-0009"/>&#13;
<p>The following figure illustrates the typical decision flow that many of us have experienced when we wish to make travel arrangements via a commercial airline. In this (greatly simplified) flow, you see how the different actors—the customer and the airline—have to interact with each other and provide information that leads to decisions. Each of the links connecting the actions and decisions show the transfer of information between these actors. When those links fail to work correctly, the entire transaction can be put at risk of failure.</p>&#13;
<figure> <img alt="Schematic illustration of Booking an Airline Flight" src="Images/c03uf001.png" class="center" width="1418" height="782"/>&#13;
</figure>&#13;
<p>Let’s look at this from the standpoint of how failures to assure confidentiality, integrity, and availability of the underlying information can cause the airline to lose business:</p>&#13;
<ul class="square" id="c03-list-0010">&#13;
<li id="c03-li-0032">Information about flights between destinations, timetables and schedules, and available fares is typically published (or “public-facing”), whether on websites, travel agency systems, or printed travel brochures. It’s freely available to anyone, competitors included. But it does have to be correct, and it does have to be there when prospective travelers are shopping around or contemplating a voyage. (Integrity and availability are required, but there’s no need for confidentiality).</li>&#13;
<li id="c03-li-0033">Once a traveler contacts the airline and begins to put trip plans together, confidentiality covers two essential needs. First, it protects the <i>customer</i> from loss of control of their PII, their travel plans, or their payment information. Next, it protects the <i>airline</i> from its competitors, who might wish to lure the customer away from them by making a better offer (in terms of price, service, schedule, or other benefits). The <i>customer</i> can always “shop aggressively” by sharing whatever information they want to with competing travel providers, but very few businesses can survive long if they tell their competitors the price and terms of transactions they’ve just made or that are “on hold” while the customer shops around!</li>&#13;
<li id="c03-li-0034"><span epub:type="pagebreak" id="Page_73" role="doc-pagebreak" aria-label="73"/>Quality of customer service indicators, such as the total time required to make a reservation, confirm it, and receive payment for it, tell the airline how well its business processes work. Should its competitors gain this information, it may reveal opportunities for them to do these processes faster, better, or cheaper, and thus gain a competitive advantage. Once again, the details of the customer service interaction need some degree of confidentiality to protect the airline’s know-how.</li>&#13;
<li id="c03-li-0035">Picture the situation if it takes six months or so to turn today’s badly served and unhappy customer encounter into useful, insightful quality-of-service information. How many customers might the airline have lost if it takes six months to learn what causes each former customer to leave? Availability of process quality information is key here; if that information is not produced in a timely manner, the company is seriously limited in its ability to improve.</li>&#13;
</ul>&#13;
<p id="c03-para-0049">Note that even an everyday business transaction such as booking an airline reservation not only contains (or requires) numerous decisions but also generates information that can and should be used to make other decisions.</p>&#13;
</section>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
<p><i>Decision assurance</i>, then, consists of protecting the availability, reliability, and integrity of the four main components of the decision process:</p>&#13;
<ul class="square" id="c03-list-0011">&#13;
<li id="c03-li-0036">The knowledge we already have (our memory and experience), including knowledge of our goals, objectives, and priorities</li>&#13;
<li id="c03-li-0037">New information we receive from others (the marketplace, customers, others in the organization, and so on)</li>&#13;
<li id="c03-li-0038">Our cognitive ability to think and reason with these two sets of information and to come to a decision</li>&#13;
<li id="c03-li-0039">Taking action to carry out that decision or to communicate that decision to others, who will then be responsible for taking action</li>&#13;
</ul>&#13;
<p id="c03-para-0051">From our CIANA+PS perspective, integrity and availability affect all four components of every decision we make (including the ones we have machines make on our behalf). Whether confidentiality is required for a particular decision, its inputs, its decision logic, or the actions or communications that are the result of making the decision, is something that the decision maker needs to decide about as well.</p>&#13;
<p>One of the most powerful decision assurance tools that managers and leaders can use at almost any organizational level is to “sanity-check” the inputs, the thinking, and the proposed actions with other people before committing to a course of action. “Does this make sense?” is a question that experience suggests ought to be asked often but isn’t. For information security specialists, checking your facts, your stored knowledge, your logic, and your planning with others can take many different forms:</p>&#13;
<ul class="square" id="c03-list-0012">&#13;
<li id="c03-li-0040">Sharing or pooling risk management information with others in your marketplace, with insurers or re-insurers, or with key stakeholders</li>&#13;
<li id="c03-li-0041">Actively participating in threat and risk reduction communities of practice, information exchanges, and community emergency response planning groups, which might include representation from local and national government authorities</li>&#13;
<li id="c03-li-0042"><span epub:type="pagebreak" id="Page_74" role="doc-pagebreak" aria-label="74"/>Using “anti-groupthink” processes and techniques to prevent your decision processes from stifling new voices or contrary views</li>&#13;
<li id="c03-li-0043">Finding ways to be “surprise-tolerant” so that unanticipated observations about day-to-day operational events can generate possible new insight</li>&#13;
<li id="c03-li-0044">Building, maintaining, and using mentors, peer groups, and trusted advisory groups, both from within the organization and from outside</li>&#13;
</ul>&#13;
</section>&#13;
<section><span id="c03-sec-0010"/>&#13;
<h3 id="head-3-27">“Common Sense” and Risk Management</h3>&#13;
<p id="c03-para-0053">It’s important to remember that most of what makes human organizations (and individual efforts) successful is our ability to recognize, think, and decide at many levels—some of which we are not consciously aware of. “Common sense,” for example, teaches us many “lessons learned” from experience: you don’t leave your car unlocked with packages on the seats if you want to come back and find those packages still in the car. You don’t leave your house or apartment unlocked when you go on vacation. You don’t leave the default user IDs of “admin” and “password” enabled on your laptops, phones, routers, switches, modems, and firewalls. (You don’t, do you?)</p>&#13;
<p id="c03-para-0054">Risk management <i>includes</i> this kind of prudent use of common sense. Risk management recognizes that before we can do anything else, we need to make sure that the blindingly obvious safety precautions, the common-sense computing hygiene measures, have already been put in place and are being used conscientiously. (We’ll look at these starting in <a href="c04.xhtml">Chapter 4</a>, “Operationalizing Risk Mitigation.”)</p>&#13;
<p id="c03-para-0055">The one drawback to common sense, as Voltaire said, is that it isn’t so common. Sometimes this is because what we call “common sense” turns out to be that we’ve made decisions intuitively, without consciously thinking them through. Other times, we’ve probably read or heard the “lessons learned” by others, but right at the moment we make a decision, we’re not using them explicitly. If those lessons lead to writing a problem-solving checklist (like a fault isolation diagram), then “common sense” becomes documented, common <i>practice</i> for us. As you’ve seen in earlier chapters, <i>due care</i> is applying common sense to ensure that the right processes, with the right steps and safeguards, have been put in place to achieve a set of goals. <i>Due diligence</i> is the follow-through that continually verifies those processes are still working right <i>and</i> that they are still necessary and sufficient to meet what’s needed.</p>&#13;
<p>Common sense can and often does suggest that there are still reasonable, prudent actions that we can take to make sure that an appropriate set of information security measures are in place and effective. Information security best practices suggest a good minimum set of “when in doubt” actions to ensure that the organization:</p>&#13;
<ul class="square" id="c03-list-0013">&#13;
<li id="c03-li-0045">Physically protects and secures information systems, information storage (paper or electronic), and supporting infrastructure</li>&#13;
<li id="c03-li-0046">Controls access by all users, visitors, and guests, such as with usernames and passwords, for all computer systems</li>&#13;
<li id="c03-li-0047">Controls disclosure and disposal of information and information systems</li>&#13;
<li id="c03-li-0048">Trains all staff (or anyone with access) on these minimum security measures</li>&#13;
</ul>&#13;
<p id="c03-para-0057"><span epub:type="pagebreak" id="Page_75" role="doc-pagebreak" aria-label="75"/>This “safe computing” or <i>computing hygiene</i> standard, is a proven place for any organization to start with. If you don’t have at least this much going for your information security program, you’re just asking for trouble!</p>&#13;
<p id="c03-para-0058">You are going to need to go beyond common sense in dealing with information risks, and that means you’ll need to <i>manage</i> those risks. This means you must augment your guesswork and intuition with informed judgment, measurement, and accountability.</p>&#13;
<aside>&#13;
<div class="top hr"><hr/></div>&#13;
<section class="feature3" aria-labelledby="head-2-38"><span id="c03-fea-0005"/>&#13;
<h3 id="head-2-38">Where’s the C3 in That Commonsense Approach?</h3>&#13;
<section><span id="c03-sec-0011"/>&#13;
<p id="c03-para-0059">Probably the most often-overlooked element of information security is what the military calls the <i>command, control, and communications</i> (or C3, sometimes written with an exponent as C<sup>3</sup>) element. Who notices that something has happened or that something has changed? Whom do they tell? How quickly? <i>Why?</i> Then who decides to have other people take what kind of action? <i>How quickly</i> must all of those conversations happen so that the organization can adapt fast enough when the risk happens, prevent or contain damage, and take the right steps to get back to normal? In other words, where is the decision assurance about risks and incidents as they occur?</p>&#13;
<p id="c03-para-0060">In the absence of a good, well-considered information risk C3 strategy and set of procedures, your coworkers could be innocently assuming that “somebody else” noticed the problems on the system or that “some other department” was handling those issues. In the face of these assumptions, nobody pays attention to the alarms or the quirks in the systems; nobody knows that something needs investigating. Nobody calls for help.</p>&#13;
<p id="c03-para-0061">This is the number one killer of “classic defense in depth,” which surrounds our valuable information assets, systems, and processes with lots of point defense tools <i>that don’t talk very well with one another</i>. Industry has created products such as security information management (SIM) systems, security event management (SEM) systems, and security information and event management (SIEM) systems to try to address this need. Putting these to effective use can help organizations bridge the gaps in their defenses, but this takes focused, sometimes intensive effort to achieve.</p>&#13;
</section>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
</section>&#13;
</section>&#13;
<section aria-labelledby="head-2-39"><span id="c03-sec-0012"/>&#13;
<h2 id="head-2-39">The Four Faces of Risk</h2>&#13;
<p>Risk, as we stated earlier, is about a <i>possible</i> occurrence of an event that leads to loss, harm, or disruption. Individuals and organizations face risk, and are confronted by its possibilities of impact, in four basic ways, as <a href="#c03-fig-0002" id="R_c03-fig-0002">Figure 3.2</a> illustrates. Three observations are important here, so important that they are worth considering as rules in and of themselves:</p>&#13;
<ul class="square" id="c03-list-0014">&#13;
<li id="c03-li-0049">Rule 1: All things will end. Systems will fail; parts will wear out. People will get sick, quit, die, or change their minds. Information will never be complete or absolutely accurate or true.</li>&#13;
<li id="c03-li-0050"><span epub:type="pagebreak" id="Page_76" role="doc-pagebreak" aria-label="76"/>Rule 2: The best you can do in the face of Rule 1 is spend money, time, and effort making <i>some</i> things more robust and resilient at the expense of others, and thus trade off the risk of one kind of failure for another.</li>&#13;
<li id="c03-li-0051">Rule 3: There’s nothing you can do to avoid Rule 1 and Rule 2.</li>&#13;
</ul>&#13;
<figure> <img alt="Schematic illustration of Four faces of risk, viewed together" src="Images/c03f002.png" class="center" width="1570" height="1008"/>&#13;
<figcaption>&#13;
<p><span class="figureLabel"><a href="#R_c03-fig-0002" id="c03-fig-0002" role="doc-backlink">FIGURE 3.2</a></span>   Four faces of risk, viewed together</p>&#13;
</figcaption>&#13;
</figure>&#13;
<aside>&#13;
<div class="top hr"><hr/></div>&#13;
<section class="feature3">&#13;
<p><img alt="Note" src="Images/note.png" class="left" width="76" height="53"/></p>&#13;
<p id="c03-para-0065">You may recognize these as the Three Laws of Thermodynamics, also expressed in song as “You Can’t Win, You Can’t Break Even, and You Can’t Get Out of the Game,” sung by Michael Jackson in the movie <i>The Wiz</i>.</p>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
<p id="c03-para-0066">Risk management, then, is trading off effort and resources <i>now</i> to reduce the possibility of a risk occurring <i>later</i>, and if it does occur, in limiting the damage it can cause to us or those things, people, and objectives we hold important. The impact or loss that can happen to us when a risk goes from being a possibility to a real occurrence—when it becomes an incident—is often looked at first in terms of how it affects our organization’s goals, objectives, systems, and our people. This provides four ways of looking at risk, no one of which is the one best right way. All of these perspectives have something to reveal to us about the information risks our organization may be facing.</p>&#13;
<p id="c03-para-0067"><span epub:type="pagebreak" id="Page_77" role="doc-pagebreak" aria-label="77"/>Think back to the Ishikawa, or fishbone, diagram we introduced in <a href="c01.xhtml">Chapter 1</a>, “The Business Case for Decision Assurance and Information Security.” The “tail” and “head” of the fishbone and the central left-to-right arrow of the backbone demonstrate the outcomes-based viewpoint. The major inputs of materials, methods, measurements, people, and machines are assets. The environment is where external threats (natural, accidental, or deliberate) can strike from. Internal threats can be visualized as the failure of any connecting arrow to “deliver the goods”—make good on the promised on-time, on-target delivery of a service, set of information, materials, labor, or other outcomes to the steps in the process that need them.</p>&#13;
<aside>&#13;
<div class="top hr"><hr/></div>&#13;
<section class="feature3" aria-labelledby="head-2-40"><span id="c03-fea-0006"/>&#13;
<h3 id="head-2-40">Bases” or “Faces”?</h3>&#13;
<section><span id="c03-sec-0014"/>&#13;
<p id="c03-para-0068">What’s the right way to think about outcomes, processes, assets, or vulnerabilities? Are they <i>perspectives</i> or are they <i>bases</i>? Both terms make sense.</p>&#13;
<p id="c03-para-0069">In accounting and business terms, we talk about a <i>basis</i> as being the foundation or starting point of a chain of decisions about the value of an asset. We’ve purchased a new computer, and that purchase price establishes its value for tax, inventory control, and accounting terms. That value is called its <i>basis</i>.</p>&#13;
</section>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
<p id="c03-para-0070">When we make an <i>estimate</i>, we are predicting a future outcome of a set of choices. That same computer has a purchase value, but to estimate what its useful life is, we have to make assumptions about how often it is used, how routine maintenance and repairs are done, and how often such machines break down under comparable use. Those assumptions, plus that purchase value, are the basis of estimate we can then calculate the useful life with.</p>&#13;
<p id="c03-para-0071">By calling these the <i>faces of risk</i>, we highlight the need for you as the SSCP to be conscious of how you <i>look</i> at things and how you perceive a situation. And that, of course, depends a lot on where you stand.</p>&#13;
<section><span id="c03-sec-0015"/>&#13;
<h3 id="head-3-28">Outcomes-Based Risk</h3>&#13;
<p id="c03-para-0072">This face of risk looks at <i>why</i> people or organizations do what they do or set out to achieve their goals or objectives. The <i>outcomes</i> of achieving those goals or objectives are the tangible or intangible results we produce, the harvest we reap. Passing the SSCP examination and earning your SSCP credential is an objective, yes, and the achievement of it is an outcome in and of itself. But in doing so, you enable or enhance your ability to be a more effective information security practitioner, which can enable you to achieve other, more strategic goals. A severe illness or injury could disrupt your ability to study for, take, and pass the examination; a family emergency could lead you to abandon that objective altogether. These are risks to the outcome (or objective) itself, and they are largely independent of the ways in which you had planned to achieve the outcome.</p>&#13;
<p id="c03-para-0073"><span epub:type="pagebreak" id="Page_78" role="doc-pagebreak" aria-label="78"/>Here’s a hypothetical example: Search Improvement Engineering (SIE) is a small software development company that makes and markets web search optimization aids targeted to mobile phone users. SIE’s chief of product development wants to move away from in-house computers, servers, and networks and start using cloud-based integrated development and test tools instead; this, she argues, will reduce costs, improve overall product quality and sustainability, and eliminate risks of disruption that owning (and maintaining) their own development computer systems can bring. The <i>outcome</i> is to improve software product quality, lower costs, and enable the company to make new products for new markets. This further supports the higher-level outcomes of organizational survival, financial health, growth, and expansion. One outcomes-based risk would be the disclosure, compromise, or loss of control over SIE’s designs, algorithms, source code, or test data to other customers operating on the cloud service provider’s systems. (We’ll look at how to evaluate and mitigate that risk in later chapters.)</p>&#13;
</section>&#13;
<section><span id="c03-sec-0016"/>&#13;
<h3 id="head-3-29">Process-Based Risk</h3>&#13;
<p id="c03-para-0074">Everything we want to achieve or do requires us to take some action; action requires us to make a decision. Even if it’s only one action that flows from one decision, that’s a <i>process</i>. In organizational terms, a <i>business process</i> takes a logical sequence of purpose, intention, conditions, and constraints and structures them as a set of systematic actions and decisions in order to carry them out. This <i>business logic</i>, and the business processes that implement it, also typically provide indicators or measurements that allow operators and managers to monitor the execution of the process, assess whether key steps are working correctly, signal completion of the process (and thus perhaps trigger the next process), or issue an alarm to indicate that attention and action are required. When a task (a process step) fails to function properly, this can either stop the process completely or lead to erroneous results.</p>&#13;
<p id="c03-para-0075">If we look further at our hypothetical SIE, we see that the company has several major sets of business processes. Human resources management processes support hiring, training, and providing salary and benefits for workers; financial processes ensure that bills are paid and invoices are issued, both of which are accurately reflected in the accounting ledgers (“the books” as the chief financial officer calls them). Software development processes define, track, and manage how customer needs and market research ideas translate into new functional requirements for products and the development and testing of those products. Customer relationship management (CRM) processes bring everything from “who is” a customer, to “What do they like to buy from us?” together with credit rating, market share, and many other factors to help SIE know how important one customer is versus another. Process-based risks to this last set of processes could be that complaints or concerns from important customers aren’t recognized quickly, properly investigated, and acted on in ways that help customers decide to stay with SIE for their search optimization software needs.</p>&#13;
<p id="c03-para-0076">Note that in this example, the <i>outcome</i> of using the processes is where we feel the <i>impact</i> of the risk becoming an incident—but it is the process that we’re focused on as we investigate “what can go wrong” as we wonder “Why are customers leaving us?”</p>&#13;
</section>&#13;
<section><span id="c03-sec-0017"/>&#13;
<h3 id="head-3-30"><span epub:type="pagebreak" id="Page_79" role="doc-pagebreak" aria-label="79"/>Asset-Based Risk</h3>&#13;
<p id="c03-para-0077">Broadly speaking, an asset is anything that the organization (or the individual) has, owns, uses, or produces as part of its efforts to achieve some of its goals and objectives. Buildings, machinery, or money on deposit in a bank are examples of hard, or <i>tangible assets</i>. The people in your organization (including you!), the knowledge that is recorded in the business logic of your business processes, your reputation in the marketplace, the intellectual property that you own as patents or trade secrets, and every bit of information that you own or use are examples of soft, or <i>intangible assets</i>. Assets are the tools you use to perform the steps in your business processes; without assets, the best business logic cannot do anything.</p>&#13;
<p id="c03-para-0078">Lots of information risk management books start with <i>information assets</i>—the information you gather, process, and use, and the business logic or systems you use in doing that—and <i>information technology assets</i>—the computers, networks, servers, and cloud services in which that information moves, resides, and is used. The unstated assumption in nearly all cases is that if the information asset or IT asset exists, it must therefore be <i>important</i> to the company or organization, and therefore, the possibility of loss or damage to that asset is a risk worth managing. This assumption may or may not still hold true. Assets also lose value over time, reflecting their decreasing usefulness, ongoing wear and tear, obsolescence, or increasing costs of maintenance and ownership. A good example of an obsolete IT asset would be a mainframe computer purchased by a university in the early 1970s for its campus computer center, perhaps at a cost of over a million dollars. By the 1990s, the growth in personal computing and network capabilities meant that students, faculty, and staff needed far more capabilities than that mainframe computer center could provide, and by 2015, it was probably far outpaced by the capabilities in a single smartphone connected to the World Wide Web and its cloud-based service provider systems. Similarly, an obsolete information asset might be the paper records of business transactions regarding products the company no longer sells, services, or supports. At some point, the <i>law of diminishing returns</i> says that it costs more to keep it and use it than the value you receive or generate in doing so.</p>&#13;
</section>&#13;
<section><span id="c03-sec-0018"/>&#13;
<h3 id="head-3-31">Threat-Based (or Vulnerability-Based) Risk</h3>&#13;
<p id="c03-para-0079">These are two sides of the same coin, really. <i>Threat actors</i> (human, intentional individuals or organizations) or hazards can cause damage and distruction leading to loss. <i>Vulnerabilities</i> are weaknesses within systems, processes, assets, and so forth that are points of potential failure. When (not if) they fail, they result in damage, disruption, and loss. Typically, threats or threat actors exploit (make use of) vulnerabilities. <i>Hazards</i> can originate from natural causes, such as storms or earthquakes, or from accidental or unintentional actions. System failures due to wear and tear, for example, are unintended. <i>Threats</i> are deliberate actions taken or contemplated by humans or instigated by humans. Such intentional attackers have purposes, goals, or objectives they seek to accomplish; Mother Nature or a careless worker does not intend to cause disruption, damage, or loss.</p>&#13;
<p id="c03-para-0080"><span epub:type="pagebreak" id="Page_80" role="doc-pagebreak" aria-label="80"/>As an example, consider a typical small office/home office (SOHO) IT network, consisting of a modem/router, a few PCs or laptops, and maybe a network attached printer and storage system. A thunderstorm can interrupt electrical power; the lack of a backup power supply is a weakness or vulnerability that the thunderstorm unintentionally exploits. By contrast, the actions of the upstairs neighbors or passers-by who try to “borrow some bandwidth” and make use of the SOHO network’s wireless connection will most likely degrade service for authorized users, quite possibly leading to interruptions in important business or personal tasks. This is deliberate action, taken by threat actors, that succeeds perhaps by exploiting poorly configured security settings in the wireless network, whether its intention was hostile (e.g., willful disruption) or merely inconsiderate.</p>&#13;
<p id="c03-para-0081">Think back to what we just discussed about process-based risks. It’s quite common for an organization to have some of its business processes contain steps for which there are no easy, affordable alternative ways to get results when that step fails to function properly. These steps are said to be “on the <i>critical path</i>” from start to finish, and thus a set of processes containing such a critical step is a critical path in and of itself. Almost without exception, critical paths and the critical steps on them are <i>vulnerabilities</i> in the business logic and the business processes that the company depends upon.</p>&#13;
<p id="c03-para-0082">It’s perhaps natural to combine the threat-based and vulnerability-based views into one perspective, since they both end up looking at vulnerabilities to see what impacts can possibly disrupt an organization’s information systems. The key question that the threat-based perspective asks, at least for human threat actors, is <i>why</i>. What is the motive? What’s the possible advantage the attacker can gain if they exploit this vulnerability? What overall gains an attacker might achieve by an attack on our information systems at all? Many small businesses (and some quite large ones) do not realize that a successful incursion into <i>their</i> systems by an attacker may only be a step in that attacker’s larger plan for disruption, damage, or harm to <i>others</i>.</p>&#13;
<p id="c03-para-0083">Note that whether you call this a “threat-based” or a “vulnerability-based” approach or perspective, you end up taking much the same action: you identify the vulnerabilities on the critical path to your high-priority objectives, and then decide what to do about them in the face of a possible threat becoming a reality and turning into an incident.</p>&#13;
<aside>&#13;
<div class="top hr"><hr/></div>&#13;
<section class="feature3"><span id="c03-fea-0007"/>&#13;
<p><img alt="Realworld" src="Images/realworld.png" class="left" width="239" height="36"/></p>&#13;
<h3 id="head-2-41">Case Study, Continued: Voter Registration and Risk Perspectives</h3>&#13;
<section><span id="c03-sec-0019"/>&#13;
<p id="c03-para-0084">Let’s use the four faces of risk to take a closer look at the voter registration and Election Day processes. We’ll build our own fishbone diagram to help us visualize and understand all of the moving parts in this real-world problem.</p>&#13;
<p>An outcomes-based view of voter registration and voting looks at what the citizens want their democracy to achieve as a functioning democracy (and not the issues or candidates <span epub:type="pagebreak" id="Page_81" role="doc-pagebreak" aria-label="81"/>being voted on themselves). Typical outcomes that such voter registration and election processes should achieve include:</p>&#13;
<ul class="square" id="c03-list-0015">&#13;
<li id="c03-li-0052">Citizen confidence in their elected officials and system of government, which translates into their willingness to obey the laws, pay their taxes, and participate in civic processes in general</li>&#13;
<li id="c03-li-0053">Fair and equitable participation of each voting demographic in the registration and election processes</li>&#13;
<li id="c03-li-0054">Compliance with legal and regulatory information confidentiality, integrity, and availability requirements</li>&#13;
<li id="c03-li-0055">The enhancement, or at least preservation, of the reputation of the local or regional government’s management and delivery of voter registration and election services</li>&#13;
<li id="c03-li-0056">No basis for a court-ordered rerun of the election or significant recount of votes</li>&#13;
<li id="c03-li-0057">Voter registration and election costs, both direct and indirect, that are kept within budget, if not minimized</li>&#13;
<li id="c03-li-0058">A political process—the final outcome of the election—that functions equitably and transparently to meet the needs of the citizens</li>&#13;
</ul>&#13;
<p id="c03-para-0086">Note that each required or intended outcome can easily be inverted to identify the risk we wish to avoid. (We’ll leave these to you to formulate as an exercise in logic.)</p>&#13;
<p>Process-based risk assessment starts by identifying key processes, which, if they fail, could cause the overall system of voter registration and the elections dependent upon it to fail:</p>&#13;
<ul class="square" id="c03-list-0016">&#13;
<li id="c03-li-0059">How are citizens and residents in the region informed of their rights and the requirements they need to fulfill to be able to register and to vote?</li>&#13;
<li id="c03-li-0060">How do citizens apply to register to vote?</li>&#13;
<li id="c03-li-0061">What other sources of information are used to validate that PII or residence information, provided by the applicant, is true and correct?</li>&#13;
<li id="c03-li-0062">What legal requirements or constraints limit how applicant information can be shared, used, or published, even in aggregate?</li>&#13;
<li id="c03-li-0063">How is registration information used on Election Day to control the voting process?</li>&#13;
<li id="c03-li-0064">How is voting done, and how are individual votes cast by voters tabulated to produce election results?</li>&#13;
<li id="c03-li-0065">How do we validate that election results accurately reflect the individual voters’ ballots?</li>&#13;
</ul>&#13;
<p><span epub:type="pagebreak" id="Page_82" role="doc-pagebreak" aria-label="82"/>Asset-based risk assessment first needs to identify the list of assets involved in voter registration and voting itself. Without these assets being available and reliable, one or more processes in voter registration, balloting, and tabulating election results cannot happen. Typically, we think of three groups of assets—information assets, technology assets (or systems assets), and people:</p>&#13;
<ul class="square" id="c03-list-0017">&#13;
<li id="c03-li-0066">Information assets might include the registration applicant files, additional files used in the validation of registration applications, and the voter rolls themselves (lists of registered voters sent to each polling place for use during voting).</li>&#13;
<li id="c03-li-0067">Information technology assets could include physical documents, as well as the containers, cabinets, boxes, or bags used to organize, store, transport, and put them to use in voting and counting of the votes. Even a simple cardboard or wooden ballot box is an asset. Computer-aided or fully computerized registration and voting systems also need machines to input, process, store, transport, and use voter registration files, voter rolls, and the ballots themselves. The communications links used to bring the voter rolls to each polling station, and to bring each station’s results together to produce the final election results, are also key assets.</li>&#13;
<li id="c03-li-0068">Don’t forget the people who make all of this work! Government employees (or contractors) process registration applications, validate applicant-provided information, and update registration records; they make sure that voter rolls are available at the polling stations. They supervise the ballot-counting processes, which a senior government official must certify as true and correct before the results are made public. Each person involved in the process is an asset, and like all assets, they have their own unique characteristics—some of which may impact their reliability!</li>&#13;
</ul>&#13;
<p>Finally, a threat-based or vulnerability-based perspective would look at each of the other three faces of risk. What can go wrong? Where are the vulnerabilities in our systems, our processes, or our people, that might represent a chance for accident or willful mischief to corrupt our voter registration and election processes?</p>&#13;
<ul class="square" id="c03-list-0018">&#13;
<li id="c03-li-0069">An individual clerk could make a mistake, or willfully decide to “misplace” some voter registration records, and thus disenfranchise many citizens by preventing them from registering in time to vote.</li>&#13;
<li id="c03-li-0070">Paper-based registration systems could be damaged by a fire, a leaky pipe, or other natural hazard; if the problem is not discovered in time, the voter rolls prepared for an election may be incomplete, also leading to disenfranchising some citizens.</li>&#13;
<li id="c03-li-0071">Voting machines can be tampered with, or may accidentally malfunction due to poor maintenance, power fluctuations, and so forth. Paper ballots can be falsified, tampered with, or “lost” at the polling station or on their way to central tabulating centers.</li>&#13;
<li id="c03-li-0072"><span epub:type="pagebreak" id="Page_83" role="doc-pagebreak" aria-label="83"/>Small, easily overlooked but vital items—like special-purpose electrical power cords—can fail to show up with the voting machines that need them, causing delays and disruption at polling places (as apparently happened in precincts in Georgia on Election Day 2018).</li>&#13;
<li id="c03-li-0073">Voters can be intimidated or prevented from entering a polling station, or otherwise believe that their individual choice is not secret.</li>&#13;
<li id="c03-li-0074">Polling stations can be disrupted or forced to close early due to bad weather or civil disobedience, and thus prevent some people from voting.</li>&#13;
</ul>&#13;
<p id="c03-para-0090">What this case study reveals is that protecting the processes of voter registration and voting itself requires us to think long and deep. We need a “cradle to grave” view, considering every event on the path from start to finish. This is how we answer the risk manager’s three big questions: what we need to defend, against what, and how we do that.</p>&#13;
</section>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
</section>&#13;
</section>&#13;
<section aria-labelledby="head-2-42"><span id="c03-sec-0020"/>&#13;
<h2 id="head-2-42">Getting Integrated and Proactive with Information Defense</h2>&#13;
<p id="c03-para-0091">Imagine for a moment a typical walled city in medieval Europe. Within the city was the castle, sitting on higher ground and surrounded by a moat, trenches, and a wall of its own. When threatened by an attacking army, farmers and villagers in the surrounding area retreated inside the city’s walls, and if the attackers breached the walls, they’d further retreat inside the castle keep itself. This layered defense had both static elements, such as the walls, moat, and trenches, as well as dynamic elements (troops could be moved about within the city). The assets being defended (the people, their livestock, food supplies, etc.) could be moved inward layer by layer as the threat increased. Watchmen, captains of the guard, and other officials would use runners to carry messages to the city’s leaders, who’d send messages back to each element of the defense.</p>&#13;
<p id="c03-para-0092">Continued advances in warfighting technology, of course, meant that static walls of stone quickly became obsolete. Yet this layered defense concept, when combined with an active, flexible command, control, and communications architecture, still dominates our thinking when we look to implement information risk management and mitigations strategies. <i>As well it should</i>. We use a layered or “top-down” approach when we design, build, and operate a business and the processes and systems that support it. Why not use that same “layers upon layers” perspective to look at how to defend it, preserve it, and keep it safe?</p>&#13;
<p id="c03-para-0093">We see by now that several ideas interact with each other, as we look to what the SSCP can do to help the organization achieve the right mix of information security, performance, and cost. Let’s start by examining how our process for designing our information defense systems mirrors the way we design, build, and operate our organization’s business processes and the IT systems that serve its needs.</p>&#13;
<p><span epub:type="pagebreak" id="Page_84" role="doc-pagebreak" aria-label="84"/>Consider a layered or structural approach to your organization’s information security needs. Whether you are trying to ensure that new business objectives can be developed, launched, and operated successfully, or you’re just trying to protect the data and systems in use today, you can look at the organization, the risks it faces, <i>and your opportunities to secure and defend it</i> in a layered fashion, as <a href="#c03-fig-0003" id="R_c03-fig-0003">Figure 3.3</a> illustrates. From the inner, most vital center of the organization on out, you might see these layers as follows:</p>&#13;
<ul class="square" id="c03-list-0019">&#13;
<li id="c03-li-0075">Core functions, assets, and information are vital to the survival of the organization.</li>&#13;
<li id="c03-li-0076">Key business processes allow trusted members of the organization to use core functions, assets, and information in the performance of their duties.</li>&#13;
<li id="c03-li-0077">Surrounding those key business processes are a variety of support processes, tasks, systems, (and people!); their work may not be vital to survival, but it does facilitate success.</li>&#13;
<li id="c03-li-0078">At the boundary to the outside world, one or more gateway functions control who has access, what they can bring in with them, what they can do as they interact with the organization and its information systems, and what they can take back outside with them when they leave.</li>&#13;
<li id="c03-li-0079">Other boundary points interface with service providers, whether as infrastructures (like power, water, or transportation) or to deliver products as services (accountants, lawyers, etc.).</li>&#13;
<li id="c03-li-0080">Other gateway functions monitor, control, or fulfill mandatory reporting and compliance needs, such as filing and paying taxes and paying bills.</li>&#13;
<li id="c03-li-0081">Public-facing boundary points provide prospective customers or partners, the news media, neighbors, and the general public with ways to learn about the organization, ask questions of it, or offer ideas or suggestions.</li>&#13;
</ul>&#13;
<figure> <img alt="Schematic illustration of the layered view" src="Images/c03f003.png" class="center" width="1487" height="701"/>&#13;
<figcaption>&#13;
<p><span class="figureLabel"><a href="#R_c03-fig-0003" id="c03-fig-0003" role="doc-backlink">FIGURE 3.3</a></span>   The layered view</p>&#13;
</figcaption>&#13;
</figure>&#13;
<p><span epub:type="pagebreak" id="Page_85" role="doc-pagebreak" aria-label="85"/>As SSCPs, we have to defend those layers of function against risk; failure to do so exposes the organization to unmanaged risks, which leaves us unable to predict what might go wrong or to plan how to respond when it does. Natural systems (such as the immune system in our bodies) and human-built systems have long recognized a few key principles when planning for defense:</p>&#13;
<ul class="square" id="c03-list-0020">&#13;
<li id="c03-li-0082">Understand your environment so that you can identify possible potential attackers and differentiate hostile actions from non-hostile ones.</li>&#13;
<li id="c03-li-0083">Deter potential attackers by having a visible, credible defensive capability and posture.</li>&#13;
<li id="c03-li-0084">Monitor potential attackers for signs that they are preparing to attack.</li>&#13;
<li id="c03-li-0085">Avoid or prevent the attack, either by means of effective deterrence, negotiation, or by other means.</li>&#13;
<li id="c03-li-0086">Detect attacks as they begin, and monitor them as they progress (or when they terminate).</li>&#13;
<li id="c03-li-0087">Deflect or delay attacks where and when possible.</li>&#13;
<li id="c03-li-0088">Degrade an attacker’s capabilities by wearing them down (attrition), stalling them (barricades, obstacles), or destroying their attack forces.</li>&#13;
<li id="c03-li-0089">Defeat the attack by sufficiently degrading deflecting, or destroying the attacking force’s units, weapons, and capabilities.</li>&#13;
</ul>&#13;
<p>Note how these concepts apply equally, whether you are considering nonintentional threats, such as “acts of Nature,” accidents, or deliberate, hostile attacks on your organization, its assets, and its interests. For example:</p>&#13;
<ul class="square" id="c03-list-0021">&#13;
<li id="c03-li-0090">A business located in a “hurricane alley” (an area known for severe storms) should learn about historic weather patterns, storm severity, and local physical, logistical, and administrative design practices that can be used in combination to survive the worst of the storms with minimal damage. Storm shelters, offsite backup capabilities, and disaster recovery plans are some of the tools the business might use.</li>&#13;
<li id="c03-li-0091">The same business, if located in a high-crime area, might use a mix of strong physical security measures, strong relationships with law enforcement and emergency services, and neighborhood outreach and engagement to provide a broad-spectrum approach to reduce the risk of being seen by local criminal elements as a “legitimate” or “easy” target.</li>&#13;
</ul>&#13;
<p>These layers of function may take physical, logical, and administrative forms throughout every human enterprise:</p>&#13;
<ul class="square" id="c03-list-0022">&#13;
<li id="c03-li-0092"><i>Physical systems elements</i> are typically things such as buildings, machinery, wiring systems, and the hardware elements of IT systems. The land surrounding the buildings, the fences and landscaping, lighting, and pavements are also some of the physical elements you need to consider as you plan for information risk management. The physical components of infrastructures, such as electric power, water, sewer, storm drains, streets and transportation, and trash removal, are also important. What’s missing from this list? <i>People</i>. People are of course physical (perhaps illogical?) elements that should not be left out of our risk management considerations!</li>&#13;
<li id="c03-li-0093"><span epub:type="pagebreak" id="Page_86" role="doc-pagebreak" aria-label="86"/><i>Administrative elements</i> are the policies, procedures, training, and expectations that we spell out for the humans in the organization to follow. These are typically the first level at which legal and regulatory constraints or directives become a part of the way the organization functions.</li>&#13;
<li id="c03-li-0094"><i>Logical elements</i> (sometimes called <i>technical elements</i>) are the software, firmware, database, or other control systems settings that you use to make the physical elements of the organization’s IT systems obey the dictates and meet the needs of the administrative ones</li>&#13;
</ul>&#13;
<p id="c03-para-0099">We no doubt used a top-down systems engineering approach when we designed our business, our business logic and its processes, and its IT infrastructures; let’s apply the same process to designing the defense of those layers of systems and functions. In doing so, let’s borrow a page or two from our history books and notice what the number one critical failing of most defenses (layered or not) turns out to be.</p>&#13;
<p id="c03-para-0100">Classical “defense-in-depth” thinking (that is, old-fashioned ideas that probably don’t work anymore) taught that each layer protected what was inside from what was outside. Oftentimes it was not very successful at defending against the threats from within—such as a trusted insider who had revealed to outsiders information about critical weaknesses in that defense, or a saboteur who had created such an exploitable weakness for an outside attacking force to take advantage of. More to the point, the classical approach <i>was</i> point by point; it looked at a specific weakness, chose a control and applied it, and in doing so often ignored a system-level need for integrated awareness, command, and control. We might say that a current defense-in-depth system is “classical” to the degree it implemented point-wise due care but failed to look at system-level due diligence needs.</p>&#13;
<p id="c03-para-0101">This lack of systems thinking encourages three critical failures on our part. We’re far too willing to ignore “blind spots” in our defenses; to blindly trust in our systems, processes, and people; and then <i>not check up on them</i> to see if they’re actually working correctly. This three-part peril is what kills most classical defense-in-depth approaches.</p>&#13;
<section><span id="c03-sec-0021"/>&#13;
<h3 id="head-3-32">Lateral Movement: Mitigate with Integrated C3</h3>&#13;
<p id="c03-para-0102">Let’s take a closer look at <a href="#c03-fig-0003">Figure 3.3</a>. It portrays four apparently separate sets of processes (and the services that support them), each supporting a distinct set of stakeholders or users of the system. These four functional pathways only seem to come together when they cross the gates into the core business processes and data at the center. This suggests that the system is designed to isolate the flow of activity along these outward, radial paths; that there is no <i>lateral movement</i> possible for an investor-user, for example, to access employee-facing functions or data. It is not until the software (or people-powered) processes that serve investor service requests reach the core that cross-channel connections between data and services may be allowed to happen.</p>&#13;
<p id="c03-para-0103">This represents good partitioning of a system; it’s isolated major use cases (customers, investors, etc.) into their own separate lanes or channels for access. The individual gates that control access and the flow of data and service requests might be routers, firewalls, <span epub:type="pagebreak" id="Page_87" role="doc-pagebreak" aria-label="87"/>or other isolation or access control enforcement devices. Taken together, these limit the capability of an attacker to use falsified credentials to enter along one pathway, search laterally (at the same level of privilege and access) for other data or process assets they might exploit, and then use those exploits for their own malicious purposes.</p>&#13;
<p id="c03-para-0104">What’s not shown on the diagram is any integration of those gates into a cohesive security-focused command, control, and communications system, sometimes referred to as C3. <a href="c05.xhtml">Chapter 5</a>, “Communications and Network Security,” will look at this in greater depth.</p>&#13;
</section>&#13;
<section><span id="c03-sec-0022"/>&#13;
<h3 id="head-3-33">Trust, but Verify</h3>&#13;
<p id="c03-para-0105">In everyday life, we have many tactics, techniques, and procedures for keeping ourselves and those we care for safe and sound. We make sure our homes have proper smoke alarms in them; we have doors and windows we can lock. We trust in these components and even in the overall design of our home and the emergency response systems in our neighborhoods to take care of us. But how often do we <i>verify</i> that this trust is well placed? Do we check the batteries in the smoke alarms, or check that all of the windows and doors are secured before we go to bed each night? Do we have our family do “fire drills” to make sure that each family member knows what to do if and when the alarms go off?</p>&#13;
<p id="c03-para-0106">This might lead you to think that the weakest link in any proactive, integrated defense system is actually the one you haven’t recently verified is still working properly—and you’d be right to think so! Our organizations will develop requirements for information security, and as SSCPs we’ll do our part to use those requirements to build in features and procedures to keep our systems safe. Those requirements must include how we plan to verify that what we built, installed, and trained people to use is actually doing the job we trust it to do. That verification is not just done at “acceptance testing” time, when we turn the systems over to the users; it must be continuous. <a href="c04.xhtml">Chapter 4</a>, “Operationalizing Risk Mitigation,” will delve into this topic in greater depth and show you how to design and carry out both acceptance testing and ongoing monitoring and assessment activities.</p>&#13;
</section>&#13;
<section><span id="c03-sec-0023"/>&#13;
<h3 id="head-3-34">Due Care and Due Diligence: Whose Jobs Are These?</h3>&#13;
<p id="c03-para-0107">This is a very important question! Legally, the doctrines of due care and due diligence provide a powerful framework in which to view how organizations, their leaders and managers, their stakeholders, and all of their employees or members have to deal with the total set of responsibilities they have agreed to fulfill. Due care and due diligence are two burdens that you willingly take on as you step into a leadership, managerial, or other responsible role in an organization. And a piece of these burdens flows down to each member of that organization, and that includes customers, suppliers, or other outsiders who deal with it.</p>&#13;
<p id="c03-para-0108">What does it mean, in a business sense, to fulfill your responsibilities? Suppose you want to open a retail business. You go to friends or family and ask them to invest money or other resources in your business. When you accept those investments, you and your investors agree that you will use them prudently, properly, legally, and effectively to set up and operate the business to achieve the goals you’ve agreed to with the investors.</p>&#13;
<p id="c03-para-0109"><span epub:type="pagebreak" id="Page_88" role="doc-pagebreak" aria-label="88"/>You take <i>due care</i> of those responsibilities, and your investors’ expectations and investments, when you set up the business, its business logic and processes, and all of its facilities, equipment, people, and supplies so that it can operate. The burden of due care requires you not only to use common sense, but also to use best practices that are widely known in the marketplace or the domain of your business. Since these represent the lessons learned through the successes or failures of others, you are being careful when you consider these; you are perhaps acting recklessly when you ignore them.</p>&#13;
<p id="c03-para-0110">As a business leader, owner, or stakeholder, you exercise <i>due diligence</i> by inspecting, auditing, monitoring, and otherwise ensuring that the business processes, people, and systems are working correctly and effectively. This means you must check that those processes and people are doing what they were set up to do and that they are performing these tasks correctly. More than that, you must also verify that they are achieving their share of the business’s goals and objectives in efficient and effective ways—in the best ways possible, in fact!</p>&#13;
<p id="c03-para-0111">Everybody in the organization has a piece of the due care and due diligence burden to carry—including the customers! Consider your relationship with your bank; you would be careless indeed if you never checked your bank balance or looked at transactions (online or on a periodic statement) and verified that each one was legitimate. In fact, under many banking laws, if the customer fails to provide timely notice to the bank of a possible fraudulent transaction, this can relieve the bank of its responsibilities to resolve it (and to reimburse the customer for any loss they suffered).</p>&#13;
<p id="c03-para-0112">Because the concepts of due care and due diligence first developed in business communities, we often think that this means that government officials somehow do not have these same burdens of responsibilities, either in law or in practice. This is not true! It is beyond the scope of this book to go into this further, but as an SSCP, you do need to be aware that everyone has a share of these burdens. By being willing to be a certified professional, you step up and accept the burden of due care by pledging to do the best job possible in designing, building, operating, and maintaining information security systems. You accept the burden of due diligence by accepting the need to ensure that such systems continue to work effectively, correctly, and efficiently, by means of monitoring their actions, analyzing the log data they produce, and keeping the organization’s leadership and management properly informed.</p>&#13;
</section>&#13;
<section><span id="c03-sec-0024"/>&#13;
<h3 id="head-3-35">Be Prepared: First, Set Priorities</h3>&#13;
<p id="c03-para-0113">Preparedness means we have to assume that some attackers will win through to their targets and that some damage will happen. Even for natural threats, such as earthquakes or hurricanes, all it takes is one “perfect storm” to wipe out our business completely—if we are not prepared for it. So how do we limit our risk—that is, not keep all of our eggs in one basket to be smashed by a single hazardous event? How do we contain it, perhaps by isolating damage so that a fire in one building does not spread to others?</p>&#13;
<p id="c03-para-0114">We should always start with a <i>current</i> set of priorities for our goals and objectives. Many organizations (and most human beings!) do the things they do and have the things they have because of decisions that they made quite some time ago. “We’ve always done it <span epub:type="pagebreak" id="Page_89" role="doc-pagebreak" aria-label="89"/>this way,” or “It’s always been my dream to own a big house on the beach” may have <i>been</i> our goals; the question is, are these <i>still</i> our most important goals today?</p>&#13;
<p id="c03-para-0115">By focusing on today’s priorities, we can often find tasks we are doing that no longer matter. Sometimes the hardest question for people or organizations to answer is, “Why are we doing this particular business <i>process</i>?” In large, established organizations, history and momentum have a lot to do with how business gets done; “We’ve always done it this way” can actually be a <i>good</i> practice, when you can be sure that the process in question is the best way to reach your organization’s <i>goal</i> or target outcome. But market conditions change, technologies evolve, people grow and learn, and more often than not, processes become outmoded, unproductive, or otherwise obsolete.</p>&#13;
<p id="c03-para-0116">Even our sense of the threats we face, or the vulnerabilities inherent to who we are (as a business) or what we do, are subject to change.</p>&#13;
<p id="c03-para-0117">Thus, the first step in defense is to know yourself (as an individual or as a business) <i>right now</i>. Know who and what you want to become. Prioritize what it takes to achieve <i>today’s</i> plan and not fall back on yesterday’s strategies. On the basis of that knowledge, look at what you need, what you have to do, and what obstacles or threats have to be faced today and in the near term—and if outcomes, objectives, processes, or assets you currently have don’t serve those priorities, then those are probably not worthy of extensive efforts to mitigate risks against them.</p>&#13;
</section>&#13;
</section>&#13;
<section aria-labelledby="head-2-43"><span id="c03-sec-0025"/>&#13;
<h2 id="head-2-43">Risk Management: Concepts and Frameworks</h2>&#13;
<p id="c03-para-0118">Recall that a <i>risk management framework</i> is a set of concepts, tools, processes, and techniques that help organize information about risk. As you’ve no doubt started to see, the job of managing risks to your information is a set of many jobs, layered together. More than that, it’s a set of jobs that changes and evolves with time as the organization, its mission, and the threats it faces evolve.</p>&#13;
<p>Let’s start by taking a quick look at NIST Special Publication 800-37r2 Risk Management Framework (RMF) for Information Systems and Organizations: A System Life Cycle Approach for Security and Privacy, Revision 2. Published in December 2018, NIST SP 800-37 Rev2 establishes a broad, overarching perspective on what it calls the fundamentals of information systems risk management. Organizational leadership and management must address these areas of concern, shown conceptually in <a href="#c03-fig-0004" id="R_c03-fig-0004">Figure 3.4</a>:</p>&#13;
<ol class="decimal" id="c03-list-0023">&#13;
<li id="c03-li-0095">Organization-wide risk management</li>&#13;
<li id="c03-li-0096">Information security and privacy</li>&#13;
<li id="c03-li-0097">System and system elements</li>&#13;
<li id="c03-li-0098">Control allocation</li>&#13;
<li id="c03-li-0099">Security and privacy posture</li>&#13;
<li id="c03-li-0100">Supply chain risk management</li>&#13;
</ol>&#13;
<p id="c03-para-0120"><span epub:type="pagebreak" id="Page_90" role="doc-pagebreak" aria-label="90"/>You can see that there’s an expressed top-down priority or sequence here. It makes little sense to worry about your IT supply chain (which might be a source of malware-infested hardware, software, and services) if leadership and stakeholders have not first come to consensus about risks and risk management at the broader, strategic level. (You should also note that in NIST’s eyes, the big-to-little picture goes from strategic, to operational, to tactical, which is how many in government and the military think of these levels. Business around the world, though, sees it as strategic, to tactical, to day-to-day operations.)</p>&#13;
<figure> <img alt="Schematic illustration of NIST RMF areas of concern" src="Images/c03f004.png" class="center" width="1528" height="729"/>&#13;
<figcaption>&#13;
<p><span class="figureLabel"><a href="#R_c03-fig-0004" id="c03-fig-0004" role="doc-backlink">FIGURE 3.4</a></span>   NIST RMF areas of concern</p>&#13;
</figcaption>&#13;
</figure>&#13;
<p>The RMF goes on by specifying seven major phases (which it calls <i>steps</i>) of activities for information risk management:</p>&#13;
<ol class="decimal" id="c03-list-0024">&#13;
<li id="c03-li-0101">Prepare</li>&#13;
<li id="c03-li-0102">Categorize</li>&#13;
<li id="c03-li-0103">Select</li>&#13;
<li id="c03-li-0104">Implement</li>&#13;
<li id="c03-li-0105">Assess</li>&#13;
<li id="c03-li-0106">Authorize</li>&#13;
<li id="c03-li-0107">Monitor</li>&#13;
</ol>&#13;
<p id="c03-para-0122">It is tempting to think of these as step-by-step sets of activities—for example, once all risks have been categorized, you then start selecting which are the most urgent and compelling to make mitigation decisions about. Real-world experience shows, though, that each step in the process reveals things that may challenge the assumptions we just finished making, causing us to reevaluate what we thought we knew or decided in that previous step. It is perhaps more useful to think of these steps as overlapping sets of attitudes and outlooks <span epub:type="pagebreak" id="Page_91" role="doc-pagebreak" aria-label="91"/>that frame and guide how overlapping sets of people within the organization do the data gathering, inspection, analysis, problem solving, and implementation of the chosen risk controls. <a href="#c03-fig-0005" id="R_c03-fig-0005">Figure 3.5</a> shows that there’s a continual ebb and flow of information, insight, and decision between and across all elements of these “steps.”</p>&#13;
<figure> <img alt="Schematic illustration of NIST RMF phased approach" src="Images/c03f005.png" class="center" width="1302" height="885"/>&#13;
<figcaption>&#13;
<p><span class="figureLabel"><a href="#R_c03-fig-0005" id="c03-fig-0005" role="doc-backlink">FIGURE 3.5</a></span>   NIST RMF phased approach</p>&#13;
</figcaption>&#13;
</figure>&#13;
<p>Although NIST publications are directive in nature for U.S. government systems, and indirectly provide strong guidance to the IT security market in the United States and elsewhere, many other information risk management frameworks are in widespread use around the world. For example, the International Organization for Standardization publishes ISO Standard 31000:2018, Risk Management Guidelines, in which the same concepts are arranged in slightly different fashion. First, it suggests that three main tasks must be done (and in broad terms, done in the order shown):</p>&#13;
<ol class="decimal" id="c03-list-0025">&#13;
<li id="c03-li-0108">Scope, Context, Criteria</li>&#13;
<li id="c03-li-0109">Risk Assessment, consisting of Risk Identification, Risk Analysis, and Risk Evaluation</li>&#13;
<li id="c03-li-0110">Risk Treatment&#13;
<p id="c03-para-0125" class="listPara1">Three additional, broader functions support or surround these central risk mitigation tasks:</p></li>&#13;
<li id="c03-li-0111">Recording and Reporting</li>&#13;
<li id="c03-li-0112">Monitoring and Review</li>&#13;
<li id="c03-li-0113">Communication and Consultation</li>&#13;
</ol>&#13;
<p id="c03-para-0126"><span epub:type="pagebreak" id="Page_92" role="doc-pagebreak" aria-label="92"/>As you can see in <a href="#c03-fig-0006" id="R_c03-fig-0006">Figure 3.6</a>, the ISO RMF also conveys a sense that on the one hand, there is a sequence of major activities, but on the other hand, these major steps or phases are closely overlapping.</p>&#13;
<figure> <img alt="Schematic illustration of ISO 31000:2018 Conceptual RMF" src="Images/c03f006.png" class="center" width="1640" height="1109"/>&#13;
<figcaption>&#13;
<p><span class="figureLabel"><a href="#R_c03-fig-0006" id="c03-fig-0006" role="doc-backlink">FIGURE 3.6</a></span>   ISO 31000:2018 Conceptual RMF</p>&#13;
</figcaption>&#13;
</figure>&#13;
<p id="c03-para-0127">It’s wise to bear in mind that each major section of these RMFs gives rise to more detailed guidance, instructions, and “lessons learned” advice. For example, NIST Special Publication 800-61 Rev. 2, Computer Security Incident Handling Guide, looks more in-depth at what happens when an information risk actually occurs and becomes an incident. Its phases of Preparation, Detection, Analysis, Containment, Eradication, Recovery, and Post-Incident Activities parallel those found in the RMF, which looks at the larger picture of information risk management. We’ll explore these in greater detail in <a href="c10.xhtml">Chapter 10</a>, “Incident Response and Recovery.”</p>&#13;
<section><span id="c03-sec-0026"/>&#13;
<h3 id="head-3-36">The SSCP and Risk Management</h3>&#13;
<p id="c03-para-0128">As an SSCP, you’ll have two major opportunities to help your organization or your business keep its information and information systems safe, secure, and reliable, as these risk management frameworks suggest. At one level, you’ll be working as a technical specialist to help implement information risk controls. You’ll be doing the day-to-day operational tasks that treat risk, ensuring that the chosen risk treatment procedures are delivering the <span epub:type="pagebreak" id="Page_93" role="doc-pagebreak" aria-label="93"/>required level of safety and security; you’ll also be part of the team that responds when risk treatments fail. As you continue to grow in your profession and gain experience and insight, you’ll be able to offer technical insight and informed opinion to your managers. It’s important, then, to see how the technical, operational details that deliver information security and decision assurance, day by day, fit within the context of the management decisions that create the risk management plans that you and others carry out.</p>&#13;
<p id="c03-para-0129">For the SSCP exam, you’ll need to have a broad awareness of the existence of standards such as these, but you won’t need to be conversant with their details. You will, however, need to be able to keep track of the context the question or issue comes up in, and be able to recognize when to shift your thinking from bigger-picture “information risk management” to more detailed, finer-grain “information security incident response” and back again.</p>&#13;
<p id="c03-para-0130">To help you in that shift of thinking, we’ll split the managerial and leadership portions of risk management and mitigation off from the technical, operational, and administrative where it makes sense. The rest of this chapter, for example, will show how SSCPs support leadership and management as they prepare the organization to manage its risks, perform its information risk assessments, and use them to develop the business impact analysis (BIA). An effective BIA provides a solid transition from understanding the risks to mitigating them. We will briefly outline the remaining steps, but use <a href="c04.xhtml">Chapter 4</a> to get into the technical, administrative, and operational details of risk mitigation.</p>&#13;
<p id="c03-para-0131">We’ll also translate the somewhat bureaucratic language that is used in the NIST RMF, and in ISO 31000:2018, into the sort of terms you’re more likely to hear and use within the workplace.</p>&#13;
<p id="c03-para-0132">So let’s get started!</p>&#13;
</section>&#13;
<section><span id="c03-sec-0027"/>&#13;
<h3 id="head-3-37">Plan, Do, Check, Act</h3>&#13;
<p id="c03-para-0133">The Project Management Institute and many other organizations talk about the basic cycle of making decisions, taking steps to carry out those decisions, monitoring and assessing the outcomes, and taking further actions to correct what’s not working and strengthen or improve what is.</p>&#13;
<p id="c03-para-0134">One important idea to keep in mind is that these cycles of Plan, Do, Check, Act (PDCA) don’t just happen one time—they repeat, they chain together in branches and sequels, and they nest one inside the other, as you can see in <a href="#c03-fig-0007" id="R_c03-fig-0007">Figure 3.7</a>. Note too that planning is a forward-looking, predictive, thoughtful, and deliberate process. We plan our next vacation <i>before</i> we put in for leave or make hotel and travel arrangements; we plan how to deal with a major disruption due to bad weather <i>before</i> the tornado season starts!</p>&#13;
<p id="c03-para-0135">The SSCP applies this framework at the daily operational level. What must you accomplish today? How will you do it? What will you need? Then, <i>do</i> those tasks. Check to see if you did them correctly <i>and</i> that you got the desired outcomes as a result. If not, take corrective action if you can, or seek help and guidance if you cannot.</p>&#13;
<span epub:type="pagebreak" id="Page_94" role="doc-pagebreak" aria-label="94"/>&#13;
<figure> <img alt="Schematic illustration of PDCA cycle diagram (simple), with subcycles" src="Images/c03f007.png" class="center" width="1547" height="863"/>&#13;
<figcaption>&#13;
<p><span class="figureLabel"><a href="#R_c03-fig-0007" id="c03-fig-0007" role="doc-backlink">FIGURE 3.7</a></span>   PDCA cycle diagram (simple), with subcycles</p>&#13;
</figcaption>&#13;
</figure>&#13;
<p>We’ll see this PDCA cycle in action here as we look at risk assessment and the decisions that come from it; <a href="c04.xhtml">Chapter 4</a> will then show PDCA in action as we look at ways to mitigate selected risks. Let’s take a closer look at these four steps:</p>&#13;
<ul class="square" id="c03-list-0026">&#13;
<li id="c03-li-0114"><i>Planning</i> is the process of laying out the step-by-step path we need to take to go from “where we are” to “where we want to be.” It’s a natural human activity; we do this every moment of our lives. Our most potent tools for planning are what Kipling called his “six honest men”—asking what, why, when, how, where, and who of almost everything we are confronted with and every decision we have to make. As an SSCP, you need those six honest teammates with you at all times!</li>&#13;
<li id="c03-li-0115"><i>Doing</i> encompasses everything it takes to accomplish the plan. From the decisions to “execute the plan” on through all levels of action, this phase is where we see people using new or different business processes to achieve what the plan needs to accomplish, using the steps the plan asks for.</li>&#13;
<li id="c03-li-0116"><i>Checking</i> is part of conducting due diligence on what the plan asked us to achieve and how it asked us to get it done. We check that tasks are getting done, on time, to specification; we check that errors or exceptions are being handled correctly. And of course, we gather this feedback data and make it available for further analysis, process improvement, and leadership decision making.</li>&#13;
<li id="c03-li-0117"><i>Acting</i> involves making decisions and taking <i>corrective</i> or <i>amplifying</i> actions based on what the <i>checking</i> activities revealed. In this phase, leaders and managers may agree that a revised plan is needed, or that the existing plan is working fine but some individual processes need some fine-tuning to achieve better results.</li>&#13;
</ul>&#13;
<p id="c03-para-0137"><span epub:type="pagebreak" id="Page_95" role="doc-pagebreak" aria-label="95"/>As with many theoretical or “school-house” models, PDCA looks simple in concept and suggests clean, well-defined breakpoints between each of its four elements. In reality, these four steps flow into and out of one another; sometimes checking will lead right back to some “modified doing,” or the day-to-day urgencies may dictate that we “get doing” before the planning is done or the checking of the actions we took based on the last version of the plan! For you as an SSCP, it’s important to recognize these separate “thought models” for dealing with situations and to recognize when you might be <i>doing</i> when you haven’t actually <i>planned</i> what to do—which would, after all, be somewhat risky behavior in itself.</p>&#13;
</section>&#13;
</section>&#13;
<section aria-labelledby="head-2-44"><span id="c03-sec-0028"/>&#13;
<h2 id="head-2-44">Risk Assessment</h2>&#13;
<p id="c03-para-0138">Risk assessment is a systematic process of identifying risks to achieving organizational priorities. There are many published handbooks, templates, and processes for doing risk assessment, and they all have several key elements that you should not lose sight of while trying to implement the chosen framework of the day.</p>&#13;
<p id="c03-para-0139">At the heart of a risk assessment process must be the organizational goals and objectives, suitably prioritized. Typically, the highest priorities are <i>existential</i> ones—ones that relate to the continued existence and health of the organization. These often involve significant threats to continued operation or significant and strategic opportunities for growth. Other priorities may be vitally important in the near term, but other options may be available if the chosen favorite fails to be successful. The “merely nice to have” objectives may fall lower in the risk assessment process. This continual reevaluation of priorities allows the risk assessment team to focus on the most important, most compelling risks first.</p>&#13;
<p id="c03-para-0140">The next major element of risk assessment is to thoroughly examine and evaluate the processes, assets, systems, information, and other elements of the organization as they relate to or support achieving these prioritized goals and objectives. This linkage of “what” and “how” with “why” helps narrow the search for system elements or process steps that, if they fail or are vulnerable to exploitation, could put these goals in jeopardy.</p>&#13;
<p id="c03-para-0141">Most risk assessment processes typically summarize their findings in some form of BIA. This relates costs (in money, time, and resources) to the organization that <i>could</i> be faced if the risk events do occur. It also takes each risk and assesses how frequently it might occur. The <i>expected cost</i> of these risks (their costs multiplied by their frequencies and probabilities of occurrences, across the organization) represents the anticipated financial impact of that risk, over time; this is a key input to making risk mitigation or control choices.</p>&#13;
<p id="c03-para-0142">Let’s see what it takes to put this kind of risk assessment process and thinking into action.</p>&#13;
<section><span id="c03-sec-0029"/>&#13;
<h3 id="head-3-38">Establish Consensus about Information Risk</h3>&#13;
<p id="c03-para-0143">Preparing the organization to <i>manage</i> its information risk requires that senior leadership, key stakeholders, and others develop and establish key working relationships and processes that focus on risk management in general and on information risk management in <span epub:type="pagebreak" id="Page_96" role="doc-pagebreak" aria-label="96"/>particular. These key individuals will need to focus attention on the relationships between organizational priorities on the one hand, and the business processes and information systems that have been built and are being used to meet those priorities on the other. This consensus should align resource allocations with those priorities.</p>&#13;
<p id="c03-para-0144">A critical task during this first step is ensuring a common understanding of the organization’s context and culture. Doing so involves reaching a consensus on <i>risk appetite</i>, or the willingness of the organization to accept risk, and on how leadership make decisions about risk. (This is sometimes referred to as the organization’s <i>risk tolerance</i>.) It is also important at this point to understand how the organization controls changes to its business processes and systems, particularly to its information technology systems.</p>&#13;
<p id="c03-para-0145">We also begin to see at this point that the organization might have a bias, or a customary way of considering risk—that is, does it view risk in terms of outcomes, processes, assets, or threats? Asset-focused risk thinkers, for example, will probably drive the organization to build its risk assessments (and its BIA) in terms of asset values and damages to those assets. Threat-based thinkers, by contrast, may try to drive the assessment conversation more in the direction of threat modeling (which we’ll examine further in <a href="c08.xhtml">Chapter 8</a>). The key is that <i>all perspectives</i> have something of value to contribute at this stage; the wiser organizations will use outcomes, processes, assets, and threats as the points to ponder as they perform their information risk assessments. No one “face of risk” is the most correct.</p>&#13;
<p id="c03-para-0146">Risk management frameworks such as NIST SP 800-37r2 and ISO 31000:2018 provide top-down guidance to organizations in setting the organizational attitude and mindset in ways that support building this consensus. These RMFs also provide specific recommendations, often in step-by-step fashion, that organizations large and small can learn from. NIST SP 800-37r2 calls this step “Prepare” as a way to emphasize how important it is to establish a common ground of understanding within the organization. The “movers and shakers” who drive the business forward have to agree, and they have to speak with a common set of words and meanings when they engage with the people who will actually do the hard work of managing and mitigating information risk. ISO 31000:2018 perhaps says this more clearly by focusing on the key <i>outcomes</i> of this step. First, we agree to where the boundaries are—what do we own and operate, and what do we count on outsiders to do on our behalf? Next, we look at context; finally, we must agree to our thresholds for accepting risk or our willingness to pay to mitigate it.</p>&#13;
<p id="c03-para-0147">The SSCP exam does not go into either RMF in great detail; nor, for that matter, would an SSCP be expected to have in-depth expertise on applying part of an RMF on the job. That said, these RMFs can help the SSCP recognize the context that their day-to-day operational duties support—and maybe help them in spotting when there are weak spots in the organization’s overall information risk management approach.</p>&#13;
</section>&#13;
<section><span id="c03-sec-0030"/>&#13;
<h3 id="head-3-39"><span epub:type="pagebreak" id="Page_97" role="doc-pagebreak" aria-label="97"/>Information Risk Impact Assessment</h3>&#13;
<p>What happens when an organization’s information is lost, compromised by disclosure to unauthorized parties, or corrupted? These questions (which reflect the CIANA+PS set of security characteristics) indicate what the organization stands to <i>lose</i> if such a breach of information security happens. Let’s illustrate with a few examples:</p>&#13;
<ul class="none" id="c03-list-0027">&#13;
<li id="c03-li-0118"><b>Personally identifying information (PII)</b>  Loss or compromise can cause customers to take their business elsewhere and can lead to criminal and civil penalties for the organization and its owners, stakeholders, leaders, and employees.&#13;
<p id="c03-para-0150" class="listPara1"><b>Company financial data, and price and cost information</b>  Loss or compromise can lead to loss of business, to investors withdrawing their funds, or to loss of business opportunities as vendors and partners go elsewhere. Can also result in civil and criminal penalties.</p>&#13;
<p id="c03-para-0151" class="listPara1"><b>Details about internal business processes</b>  Loss could lead to failures of business processes to function correctly; compromise could lead to loss of competitive advantage, as others in the marketplace learn how to do your business better.</p>&#13;
<p id="c03-para-0152" class="listPara1"><b>Risk management information</b>  In the worst case, loss or compromise of your risk management information could provide attackers with valuable technical and operational intelligence insights, making your systems and your organization all the more vulnerable to attack. Additionally, loss or compromise could lead to insurance policies being canceled or premiums being increased, as insurers conclude that the organization cannot adequately fulfill its <i>due diligence</i> responsibilities.</p></li>&#13;
</ul>&#13;
<p id="c03-para-0153">When we view information in such terms—as “What does it cost us if we lose it?”—we decide how vital the information is to us. What this categorization or classification really does is tell us <i>how important it is to protect that information, based on possible loss or impact</i>. We categorize our possible losses, in terms of severity of damage, impact, or costs; we also categorize them in terms of outcomes, processes, and assets they have or depend on. Finally, we categorize them by threat or common vulnerabilities. This kind of risk analysis can help us identify critical locations, elements, or objectives that could be putting the entire organization at risk; in doing so, that focuses our risk analysis further.</p>&#13;
</section>&#13;
<section><span id="c03-sec-0031"/>&#13;
<h3 id="head-3-40">Information Classification and Categorization</h3>&#13;
<p id="c03-para-0154">Some of us are familiar with simple hierarchical information classification systems used by governments and military services. These often start with “Unclassified” as their lowest level and move up through “For Official Use Only,” “Confidential,” “Secret,” and “Top Secret” as their way of broadly outlining how severely a nation would be impacted if the information was disclosed, stolen, or otherwise compromised. Yet even these cannot stay simple for long. Businesses, private organizations, and the military have another aspect of data categorization in common: the concept of <i>need to know</i>. Also known as <i>least privilege</i>, need to know limits who has access to read, use, or modify data based on whether their job functions require them to do so. Thus, a school’s purchasing department staff have a need to know about suppliers, prices, specific purchases, and so forth, but they do not need to know any of the PII pertaining to students, faculty, or other staff members. Need to know leads to compartmentalization of information approaches, which create procedural boundaries (administrative controls) around such sets of information. (We’ll discuss this more in <a href="c06.xhtml">Chapter 6</a>, “Identity and Access Control.”) All of this leads to needing more powerful ways to group similar sets of information (such as all PII pertaining to students) <span epub:type="pagebreak" id="Page_98" role="doc-pagebreak" aria-label="98"/>into groups based on common levels of impacts from compromise and on common security measures that should be used to protect it.</p>&#13;
<p>This process of grouping or categorizing potential impacts from different types of risks leads directly to the three tasks of <i>security classification</i>, <i>categorization</i>, and <i>baselining</i> for all the organization’s information assets. These tasks are defined as follows:</p>&#13;
<ul class="square" id="c03-list-0028">&#13;
<li id="c03-li-0119"><i>Security classification</i> (often shortened to <i>classification</i>) identifies types of information and assigns a label to it that reflects the potential for impact or damage to the organization, its activities, or its objectives, if a risk event should lead to compromise of any of the security characteristics related to that information. Classification must reflect legal or compliance requirements that dictate the sensitivity of information.</li>&#13;
<li id="c03-li-0120"><i>Security categorization</i> (or categorization, for short) groups together similarly classified types of information and associates or links those types to laws, standards, contractual, or other compliance frameworks that may specify required security controls or protection measures that must be used.</li>&#13;
<li id="c03-li-0121">A <i>security baseline</i> is established for a given category of data by associating the minimum required controls with that data type.</li>&#13;
</ul>&#13;
<p id="c03-para-0156">Classifying the organization’s information assets (that is, the data, information, and knowledge itself—and <i>not</i> the media on which it is recorded) provides a powerful way to align risk management, security controls, and job or workflow designs with organizational goals, objectives, and priorities. We’ll see in <a href="c12.xhtml">Chapter 12</a> how this alignment of security functions, from classification through continuous assessment, is (or should be) a major component of an effective security program.</p>&#13;
<p id="c03-para-0157">Categorizing data types with similar security levels and needs provides a consistency check. For example, suppose that a manufacturing company has safety-critical data that relates to four different sources of safety compliance regulations (such as chemical and hazardous materials handling, machinery operation, and autonomous systems). Looking across all of these safety groups might reveal common assumptions in the ways in which workflows and processes were designed; these assumptions may need further assessment and might possibly be home to exploitable vulnerabilities in their implementations.</p>&#13;
<p id="c03-para-0158">The security baseline provides a common frame of reference that the organization can use to create requirements, designs, processes, and procedures for labeling, handling, storing, and protecting the various types of data it uses. In this way, changes to the threat landscape, to systems and applications, or to security technologies can be focused in on the specific security needs of each data type. This helps the organization spend the right amount of effort to get the right protection, rather than ending up in what might be a blanket overspend to protect everything to the highest possible level of security.</p>&#13;
<p id="c03-para-0159">For example, an online pharmacy might use a subset of each customer’s PII, their credit, debit, or other payment card information, information about their insurance carrier, and then the details of each prescription or over-the-counter drug purchased by the customer. Depending upon the country of jurisdiction, each of those types of data may require different protections, such as different levels of encryption, or be subject to audit or inspection at different frequencies. Safety considerations would require that the pharmacy can quickly link any drug recall notices to individual purchases based on drug batch or lot numbers, dates, <span epub:type="pagebreak" id="Page_99" role="doc-pagebreak" aria-label="99"/>and so on. Insurance portability and privacy laws may specify other special protection needs. Each type of data may also have different maximum retention periods specified by law. Finally, the pharmacy would need to protect its overall wholesale purchase, inventory, and order history data from inadvertent access, breach, or loss. Just for its primary line of business, five different classification schemes or levels might be needed, each associated with the specific laws, standards, or contracts that dictate the protection required.</p>&#13;
<p id="c03-para-0160">This might result in security classification labels for <i>privacy</i>, <i>payment</i>, <i>insurance</i>, <i>safety</i>, and <i>logistics</i> data. They may additionally need classifications for their <i>human resources</i> and <i>financial</i> data, along with <i>company proprietary</i> as a label (and set of handling procedures) for their workflow process knowledge and other trade secrets. Note that these do not ladder up in a simple list from highest to lowest security level; each is a different set, the sets are disjoint (in set theory terms), and each needs its own set of protection and handling procedures. If a single “system high” classification was used instead, then any employee would have access privileges to any data based upon its (one and only) security classification; this would probably violate compliance requirements and might introduce other security risks as well.</p>&#13;
<p id="c03-para-0161">For classification programs to be successful, several conditions need to be met. First, each information asset must have an <i>asset owner</i> within the organization, one who understands the business logic for its use and can speak authoritatively about potential impacts should it be compromised in any way. Next, the classification scheme itself needs to balance robustness with simplicity. Too simple, and everything is “top secret” and nobody really understands what that means; too complicated, with too many layers and levels, and it becomes hard to use. Either way, human error will result in mishandling of sensitive data, possibly leading to compromise or loss. Finally, as we’ll see in <a href="c08.xhtml">Chapter 8</a>, “Hardware and Systems Security” there need to be procedures in place for establishing data retention limits and for proper disposal of information when it is no longer required.</p>&#13;
</section>&#13;
<section><span id="c03-sec-0032"/>&#13;
<h3 id="head-3-41">Risk Analysis</h3>&#13;
<p id="c03-para-0162">Risk analysis is a complex undertaking and often involves trying to sort out what can cause a risk to become an incident. <i>Root cause analysis</i> looks to find what the underlying vulnerability or mechanism of failure is that leads to the incident, for example. By contrast, <i>proximate cause analysis</i> asks, “What was the last thing that happened that caused the risk to occur?” (This is sometimes called the “last clear opportunity to prevent” the incident, a term that insurance underwriters and their lawyers often use.) Our earlier example of backing your car out of the driveway, only to run over a child’s bicycle left in the wrong place, illustrates these ideas. You could have looked first, maybe even walked around the car before you got in and started to drive; you had the last clear opportunity to prevent damage, and thus your actions were the proximate cause. (You failed in your due diligence, in other words.) Your child, however, is the one who left the bicycle in the wrong place; the root of the problem may be the failure to help your child learn and appreciate what his responsibility of due care for his bicycle requires. And who was responsible for teaching due care to your child? (A word of advice: don’t say “My spouse.”)</p>&#13;
<p id="c03-para-0163">We’ve looked at a number of examples of risks becoming incidents; for each, we’ve identified an <i>outcome</i> that describes what might happen (customers go to our competitors; we <span epub:type="pagebreak" id="Page_100" role="doc-pagebreak" aria-label="100"/>must get our car and the bicycle repaired). Outcomes are part of the <i>basis of estimate</i> with which we can make two kinds of <i>risk assessments</i>: quantitative and qualitative.</p>&#13;
<section><span id="c03-sec-0033"/>&#13;
<h4 id="head-4-8">Quantitative Risk Assessment: Risk by the Numbers</h4>&#13;
<p><i>Quantitative assessments</i> use simple techniques (like counting possible occurrences, or estimating how often they might occur) along with estimates of the typical cost of each loss:</p>&#13;
<ul class="square" id="c03-list-0029">&#13;
<li id="c03-li-0122"><i>Single loss expectancy (SLE)</i>: Usually measured in monetary terms, SLE is the total cost you can reasonably expect should the risk event occur. It includes immediate and delayed costs, direct and indirect costs, costs of repairs, and restoration. In some circumstances, it also includes lost opportunity costs, or lost revenues due to customers needing or choosing to go elsewhere.</li>&#13;
<li id="c03-li-0123"><i>Annual rate of occurrence (ARO)</i>: ARO is an estimate of how often during a single year this event could reasonably be expected to occur.</li>&#13;
<li id="c03-li-0124"><i>Annual loss expectancy (ALE)</i>: ALE is the total expected losses for a given year and is determined by multiplying the SLE by the ARO.</li>&#13;
<li id="c03-li-0125"><i>Safeguard value</i>: This is the estimated cost to implement and operate the chosen risk mitigation control. You cannot know this until you’ve chosen a risk control or countermeasure and an implementation plan for it; we’ll cover that in the next chapter.</li>&#13;
</ul>&#13;
<p>Other numbers associated with risk assessment relate to how the business or organization deals with time when its systems, processes, and people are not available to do business. This “downtime” can often be expressed as a mean (or average) allowable downtime, or a maximum downtime. Times to repair or restore minimum functionality, and times to get everything back to normal, are also some of the numbers the SSCP will need to deal with. For example:</p>&#13;
<ul class="square" id="c03-list-0030">&#13;
<li id="c03-li-0126">The <i>maximum acceptable outage (MAO)</i> is the maximum time that a business process or task cannot be performed without causing intolerable disruption or damage to the business. Sometimes referred to as the <i>maximum tolerable outage (MTO)</i>, or the <i>maximum tolerable period of disruption (MTPOD)</i>, determining this maximum outage time starts with first identifying <i>mission-critical outcomes</i>. These outcomes, by definition, are vital to the ongoing success (and survival!) of the organization; thus, the processes, resources, systems, and no doubt people they require to properly function become <i>mission-critical resources</i>. If only <i>one</i> element of a mission-critical process is unavailable, and no immediate substitute or workaround is at hand, then the MAO clock starts ticking.</li>&#13;
<li id="c03-li-0127">The <i>mean time to repair (MTTR)</i>, or <i>mean time to restore</i>, reflects our average experience in doing whatever it takes to get the failed system, component, or process repaired or replaced. The MTTR must include time to get suitable staff on scene who can diagnose the failure, identify the right repair or restoration needed, and draw from parts or replacement components on hand to effect repairs. MTTR calculations should also include time to verify that the repair has been done correctly <i>and that the repaired system works correctly</i>. This last requirement is very important—it does no good at <span epub:type="pagebreak" id="Page_101" role="doc-pagebreak" aria-label="101"/>all to swap out parts and say that something is fixed if you cannot assure management and users that the repaired system is now working the way it needs to in order to fulfill mission requirements.</li>&#13;
</ul>&#13;
<p>These types of quantitative assessments help the organization understand what a risk can do when it actually happens (becomes an incident) and what it will take to get back to normal operations and clean up the mess it caused. One more important question remains: <i>how long to repair and restore is too long?</i> Two more “magic numbers” shed light on this question:</p>&#13;
<ul class="square" id="c03-list-0031">&#13;
<li id="c03-li-0128">The <i>recovery time objective (RTO)</i> is the amount of time in which system functionality or ability to perform the business process must be back in operation. Note that the RTO must be less than or equal to the MAO (if not, there’s an error in somebody’s thinking). As an <i>objective</i>, RTO asks systems designers, builders, maintainers, and operators to strive for a better, faster result. But be careful what you ask for; demanding too rapid an RTO can cause more harm than it deflects by driving the organization to spend far more than makes bottom-line sense.</li>&#13;
<li id="c03-li-0129">The <i>recovery point objective (RPO)</i> measures the <i>data loss</i> that is tolerable to the organization, typically expressed in terms of how much data needs to be loaded from backup systems in order to bring the operational system back up to where it needs to be. For example, an airline ticketing and reservations system takes every customer request as a transaction, copies the transactions into log files, and processes the transactions (which causes updates to its databases). Once that’s done, the transaction is considered completed. If the database is backed up in its entirety once a week, let’s say, then if the database crashes five days after the last backup, that backup is reloaded and then five days’ worth of transactions must be reapplied to the database to bring it up to where customers, aircrew, airport staff, and airplanes expect it to be. Careful consideration of an RPO allows the organization to balance costs of routine backups with time spent reapplying transactions to get back into business.</li>&#13;
</ul>&#13;
<p>We’ll go into these numbers (and others) in greater depth in <a href="c10.xhtml">Chapter 10</a> as you learn how to help your organization plan for and manage its response to actual information security and assurance incidents. It’s important that you realize that these numbers play three critical roles in your integrated, proactive information defense efforts. All of these quantitative assessments (plus the qualitative ones as well) help you achieve the following:</p>&#13;
<ul class="square" id="c03-list-0032">&#13;
<li id="c03-li-0130">Establish the “pain points” that lead to information security requirements that can be measured, assessed, implemented, and verified.</li>&#13;
<li id="c03-li-0131">Shape and guide the organization’s thinking about risk mitigation control strategies, tactics, and operations, and keep this thinking within cost-effective bounds.</li>&#13;
<li id="c03-li-0132">Dictate key business continuity planning needs and drive the way incident response activities must be planned, managed, and performed.</li>&#13;
</ul>&#13;
<p id="c03-para-0170">One final thought about the “magic numbers” is worth considering. The organization’s leadership have their stakeholders’ personal and professional fortunes and futures in their hands. Exercising due diligence <i>requires</i> that management and leadership be able to show, by the numbers, that they’ve fulfilled that obligation and brought it back from the brink of <span epub:type="pagebreak" id="Page_102" role="doc-pagebreak" aria-label="102"/>irreparable harm when disaster strikes. Those stakeholders—the organization’s investors, customers, neighbors, and workers—need to trust in the leadership and management team’s ability to meet the bottom line every day. Solid, well-substantiated numbers like these help the stakeholders trust, but verify, that their team is doing their job.</p>&#13;
<aside>&#13;
<div class="top hr"><hr/></div>&#13;
<section class="feature3" aria-labelledby="head-2-45"><span id="c03-fea-0008"/>&#13;
<h3 id="head-2-45">Calculating Quantitative Risks for a Small Business</h3>&#13;
<section><span id="c03-sec-0034"/>&#13;
<p id="c03-para-0171">Jayne owns a small 3D-printing facility that provides custom parts for various design and engineering firms. She deals with customers across the nation via the Internet. Her business is located in an earthquake zone, and a sufficiently strong earthquake could devastate her facility and damage or destroy her 3D-printing machines. It would cost up to $500,000 to replace her facility or to rebuild it in a new location after such a disaster. It could take six months to get new equipment installed in a new or repaired facility and get back in business. This could lead to a loss of $200,000 in revenues. Official government estimates suggest that such a devastating earthquake might happen once every 50 years. Jayne needs to appreciate how much she stands to lose if such an earthquake strikes her business.</p>&#13;
<p>First, how much does she expect to lose altogether if such an earthquake occurs? This is her <i>single loss expectancy</i>, which is the sum of all costs she incurs plus all lost business revenues because of the earthquake. This is calculated as follows:</p>&#13;
<ul class="none" id="c03-list-0033">&#13;
<li id="c03-li-0133">Single loss expectancy = (replacement costs) + (lost revenue)</li>&#13;
<li id="c03-li-0134">SLE = $500,000 + $200,000 = $700,000</li>&#13;
</ul>&#13;
<p>Next, let’s look at how often Jayne might expect or anticipate such a loss to occur. For natural events such as earthquakes or storms, governments usually publish data about expected rates of occurrence. In Jayne’s case, the published annual rate of occurrence for such an earthquake is once in each 50-year period; we must normalize that to show number of occurrences anticipated in any single year:</p>&#13;
<ul class="none" id="c03-list-0034">&#13;
<li id="c03-li-0135">ARO = (number of occurrences) / (number of years)</li>&#13;
<li id="c03-li-0136">ARO = 1/50 = 0.02</li>&#13;
</ul>&#13;
<p>Now Jayne wants to know how much of a loss, in any given year, she can anticipate because of such a major earthquake. She gets this annual loss expectancy (ALE) by simply multiplying the loss on a single event by the probability of that event occurring in any given year:</p>&#13;
<ul class="none" id="c03-list-0035">&#13;
<li id="c03-li-0137">Annual loss expectancy = SLE * ARO</li>&#13;
<li id="c03-li-0138">ALO = $700,000 * 0.02 = $14,000</li>&#13;
</ul>&#13;
<p id="c03-para-0176">One possible risk mitigation strategy would be to sign a “warm standby” agreement with another 3D-printing firm, one using similar equipment and software systems but located away from the earthquake-prone area where Jayne’s business is located. The safeguard <span epub:type="pagebreak" id="Page_103" role="doc-pagebreak" aria-label="103"/>value here might be minimal (the costs of negotiating the agreement); it could also lead to Jayne having an inexpensive “surge” capacity for her business. But she now has to worry if the warm standby provider will actually be there in case of an earthquake and be able to meet her customers’ needs on time.</p>&#13;
<p>Jayne also has to worry about electrical power outages due to storms; 3D printing is spoiled if power is lost any time during the print-and-cure operation cycle, making the product unusable. Typically about four hours of lost time is involved to clean up the printers and reset them to restart the spoiled job. The costs of scrapping the current print job, cleaning up, and resetting can reach about $250 in materials and staff time. Her production schedule normally provides sufficient slack time for one rework cycle per customer job, so she hasn’t lost revenues because of such outages (yet!). During the business day, Jayne has noticed that such storms cause power outages about four times per month during the rainy season, which lasts three months; in other months she’s experienced no power outages. How would Jayne assess this risk in terms of expected impacts to her business?</p>&#13;
<ul class="none" id="c03-list-0036">&#13;
<li id="c03-li-0139">SLE = ______ + ______</li>&#13;
<li id="c03-li-0140">ARO = ______ / ______</li>&#13;
<li id="c03-li-0141">ALE = ______ * ______</li>&#13;
</ul>&#13;
<p id="c03-para-0178">With a single loss expectancy of $250, and an annual loss rate of 12 times per year (four times per month during three rainy months), Jayne can expect up to $3,000 in annual losses due to weather-induced electrical power interruptions. Common sense might suggest that an uninterruptible power supply might be a prudent investment!</p>&#13;
</section>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
</section>&#13;
<section><span id="c03-sec-0035"/>&#13;
<h4 id="head-4-9">Qualitative Risk Assessment</h4>&#13;
<p id="c03-para-0179"><i>Qualitative assessments</i> focus on an inherent quality, aspect, or characteristic of the risk as it relates to the outcome(s) of a risk occurrence. “Loss of business” could be losing a few customers, losing many customers, or closing the doors and going out of business entirely!</p>&#13;
<p id="c03-para-0180">So, which assessment strategy works best? The answer is <i>both</i>. Some risk situations may present us with things we can count, measure, or make educated guesses about in numerical terms, but many do not. Some situations clearly identify <i>existential threats</i> to the organization (the occurrence of the threat puts the organization completely out of business); again, many situations are not as clear-cut. Senior leadership and organizational stakeholders find both qualitative and quantitative assessments useful and revealing.</p>&#13;
<p id="c03-para-0181">Qualitative assessment is often used when managers or risk analysts believe that they do not have sufficient data to support a rigorous quantitative analysis. The processes being assessed for impact might be new or unique; the organization or even its industry and market may not have sufficient experience with an activity to make a reliable <i>quantitative</i> estimate of frequency of occurrence or impact. That said, the organization may find that it has more than enough data (from design, testing, simulation, or market research) than it really needs to make a reasonable quantitative estimate with.</p>&#13;
</section>&#13;
<section><span id="c03-sec-0036"/>&#13;
<h4 id="head-4-10"><span epub:type="pagebreak" id="Page_104" role="doc-pagebreak" aria-label="104"/>The Risk Register</h4>&#13;
<p id="c03-para-0182">At this point, the organization or business needs to be building a <i>risk register</i>, a central repository or knowledge bank of the risks that have been identified in its business and business process systems. This register should be a living document, constantly refreshed as the company moves from risk identification through mitigation to the “new normal” of operations after instituting risk controls or countermeasures.</p>&#13;
<p id="c03-para-0183">As an internal document, a company’s risk register is a compendium of its weaknesses and should be considered as closely held, confidential, proprietary business information. It provides a would-be attacker, competitors, or a disgruntled employee with powerful insight into ways that the company might be vulnerable to attacks. This need to protect the confidentiality of the risk register becomes even more acute as the risk register is updated from first-level outcomes or process-based identification through impact assessments, and then linked (as you’ll see in the next chapter, “Operationalizing Risk Mitigation”) with systems vulnerability or root cause/proximate cause assessments.</p>&#13;
<p id="c03-para-0184">There is no one agreed or best format or structure for a risk register, although many vendors provide platforms and systems to assist businesses in organizing all of their risk management information and processes. These details are beyond the scope of the SSCP exam, but you’ll need to be aware of the role that a risk register should play in planning and conducting information risk management efforts.</p>&#13;
</section>&#13;
<section><span id="c03-sec-0037"/>&#13;
<h4 id="head-4-11">Common Vulnerabilities</h4>&#13;
<p id="c03-para-0185">Many nations conduct or sponsor efforts to collect and publish information about system vulnerabilities that are commonly found in commercial-off-the-shelf (COTS) IT systems and elements or that result from common design or system production weaknesses. In the United States, the Mitre Corporation maintains its database of Common Vulnerabilities and Exposures (or CVE) information as a public service; this data is made freely available to anyone, from anywhere, without restriction. Mitre is one of several federally funded research and development corporations (FFRDCs) that research science and technology topics in the national interest; many of its findings are made available as published reports or databases. Mitre operates the National Cybersecurity FFRDC (NCF), which as of this writing is the only federally funded research center for cybersecurity and vulnerability assessment. Its website, <code><a href="https://cve.mitre.org/">https://cve.mitre.org/</a></code>, has a rich set of information and resources that SSCPs should become familiar with. In the United States, the National Institute of Standards and Technologies (NIST) operates the National Vulnerability Database, <code><a href="https://nvd.nist.gov/">https://nvd.nist.gov/</a></code>; in the United Kingdom, these roles are provided by the Government Communications Headquarters (GCHQ, which is roughly equivalent to the U.S. National Security Agency), which you can find at its National Cyber Security Centre at <code><a href="http://www.ncsc.gov.uk">www.ncsc.gov.uk</a></code>.</p>&#13;
</section>&#13;
</section>&#13;
<section><span id="c03-sec-0038"/>&#13;
<h3 id="head-3-42"><span epub:type="pagebreak" id="Page_105" role="doc-pagebreak" aria-label="105"/>The Business Impact Analysis</h3>&#13;
<p id="c03-para-0186">The business impact analysis (BIA) is where the rubber hits the road, so to speak. Risk management must be a balance of priorities, resources, probabilities, and impacts, as you’ve seen throughout this chapter. All this comes together in the BIA. As its name implies, the BIA is a consolidated statement of how different risks could impact the prioritized goals and objectives of an organization.</p>&#13;
<p id="c03-para-0187">The BIA reflects a combination of due care and due diligence in that it combines “how we do business” with “how we know how well we’re doing it.”</p>&#13;
<p>There is no one right, best format for a BIA; instead, each organization must determine what its BIA needs to capture and how it has to present it to achieve a mix of purposes:</p>&#13;
<ul class="square" id="c03-list-0037">&#13;
<li id="c03-li-0142">BIAs should inform, guide, and shape risk management decisions by senior leadership.</li>&#13;
<li id="c03-li-0143">BIAs should provide the insight to choose a balanced, prudent mix of risk mitigation tactics and techniques.</li>&#13;
<li id="c03-li-0144">BIAs should guide the organization in accepting residual risk to goals, objectives, processes, or assets in areas where this is appropriate.</li>&#13;
<li id="c03-li-0145">BIAs may be required to meet external stakeholder needs, such as for insurance, financial, regulatory, or other compliance purposes.</li>&#13;
</ul>&#13;
<p id="c03-para-0189">You must recognize one more important requirement at this point: to be effective, a BIA must be <i>kept up to date</i>. The BIA must reflect today’s set of concerns, priorities, assets, and processes; it must reflect today’s understanding of threats and vulnerabilities. Outdated information in a BIA could at best lead to wasted expenditures and efforts on risk mitigation; at worst, it could lead to failures to mitigate, prevent, or contain risks that could lead to serious damage, injury, or death, or possibly put the organization out of business completely.</p>&#13;
<p id="c03-para-0190">At its heart, making a BIA is pretty simple: you identify what’s important, estimate how often it might fail, and estimate the costs to you of those failures. You then rank those possible impacts in terms of which basis for risk best suits your organization, be that outcomes, processes, assets, or vulnerabilities. For all but the simplest and smallest of organizations, however, the amount of information that has to be gathered, analyzed, organized, assessed, and then brought together in the BIA can be overwhelming. The BIA is one of the most critical steps in the information risk management process, end to end; it’s also perhaps the most iterative, the most open to reconsideration as things change, and the most in need of being kept alive, current, and useful. Most of that is well beyond the scope of the SSCP examination, and so we won’t go into the mechanics of the business impact analysis process in any further detail. As an SSCP, however, you’ll be expected to continue to grow your knowledge and skills, thus becoming a valued contributor to your organization’s BIA.</p>&#13;
</section>&#13;
<section><span id="c03-sec-0039"/>&#13;
<h3 id="head-3-43"><span epub:type="pagebreak" id="Page_106" role="doc-pagebreak" aria-label="106"/>From Assessments to Information Security Requirements</h3>&#13;
<p id="c03-para-0191">Two sets of information provide a rich source of information security requirements for an organization. The first is the legal, regulatory, and cultural context in which the organization must exist. As stated before, failure to fulfill these obligations can put the organization out of existence, and its leaders, owners, stakeholders (and even its employees) at risk of civil or criminal prosecution. The second set of information that should drive the synthesis of information security requirements is the organization’s BIA.</p>&#13;
<p id="c03-para-0192">There are typically two major ways that information security requirements take form or are expressed or stated within an organization. The first is to write a system requirements specification (SRS), which is a formal document used to capture high-level statements of function, purpose, and intent. An SRS also contains important system-level constraints. It guides or directs analysts and developers as they design, build, test, deploy, and maintain an information; it also drives end-user training activities.</p>&#13;
<p>Organizations also write and implement policies and procedures that state what the information security requirements are and what the people in the organization need to do to fulfill them and comply with them:</p>&#13;
<ul class="square" id="c03-list-0038">&#13;
<li id="c03-li-0146"><i>Policies</i> are broad statements of direction and intention; in most organizations, they establish direction and provide constraints to leaders, managers, and the workforce. Policies direct or dictate what should be done, to what standards of compliance, who does it, and why they should do it. Policies are usually approved (“signed out”) by senior leadership, and are used to guide, shape, direct, and evaluate the performance of the people who are affected by the policies; they are thus considered administrative in nature.</li>&#13;
<li id="c03-li-0147"><i>Procedures</i> take the broad statements expressed in policies and break them down into step-by-step detailed instructions to those people who are assigned responsibility to perform them. Procedures state how a task needs to be performed and should also state what constraints or success criteria apply. As instructions to people who perform these tasks, procedures are administrative in nature.</li>&#13;
</ul>&#13;
<p id="c03-para-0194">You might ask which should come first, the SRS or the policies and procedures. Once senior leadership agrees to a statement of need, it’s probably faster to publish a policy and a new procedure than it is to write the SRS, design the system, test it, deliver it, and train users on the right ways to use it. But be careful! It often takes a <i>lot</i> of time and effort for the people in an organization to operationalize a new policy and the procedures that come with it. Overlooking this training hurdle can cause the new policy or procedures to fail.</p>&#13;
<span epub:type="pagebreak" id="Page_107" role="doc-pagebreak" aria-label="107"/>&#13;
<aside>&#13;
<div class="top hr"><hr/></div>&#13;
<section class="feature3" aria-labelledby="head-2-46"><span id="c03-fea-0009"/>&#13;
<h3 id="head-2-46">FERPA: From Law Through Policy to Requirements</h3>&#13;
<section><span id="c03-sec-0040"/>&#13;
<p id="c03-para-0195">In the United States, the Family Educational Rights and Privacy Act (FERPA) provides the legal requirements pertaining to the collection, storage, use, sharing, and disposal of individual educational records. Schools, training companies, and other organizations that must meet FERPA’s requirements have to ensure that their people who have access to “FERPA-protected information” are trained to understand their legal responsibilities (their <i>due care</i> burdens). Records systems, whether automated or not, have to meet various access control standards and practices. FERPA-protected information cannot be disclosed to other persons or organizations except in specific circumstances as defined in law.</p>&#13;
<p id="c03-para-0196">Suppose a school is converting its paper-based records system over to a cloud-hosted system using a platform-as-a-service (PAAS) approach. The “platform” would be a database product with built-in functions that implement student admission, registration, enrollment, grading, transcripts, attendance, or other functions. As the school shops around for such a PAAS provider, one key question the school should ask is, “How does your platform ensure FERPA compliance?” The school might also want to thoroughly understand how the PAAS provider will upload its paper records into the new system, and make sure that this process does not involve any opportunities for FERPA-protected information to “leak” outside of the hands of those who are trained to protect it.</p>&#13;
<p id="c03-para-0197">In the meantime, the school needs to have written policies and procedures in place that dictate who can access the records (who has keys to the filing cabinets, for example), as well as who has to approve release of information from those records to someone who is not a FERPA-certified school official.</p>&#13;
<p id="c03-para-0198">By the way, it’s important to note that many other nations, as well as the European Union, have their own “FERPA-like” legal requirements. How might these impact a company that provides online educational resources, classes and support for home-study children who might live abroad?</p>&#13;
</section>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
</section>&#13;
</section>&#13;
<section aria-labelledby="head-2-47"><span id="c03-sec-0041"/>&#13;
<h2 id="head-2-47">Four Choices for Limiting or Containing Damage</h2>&#13;
<p id="c03-para-0199">Four strategic choices exist when we think of how to protect prioritized assets, outcomes, or processes. These choices are at the strategic level, because just the nature of them is comparable to “life-or-death” choices for the organization. A strategic risk might force the company to choose between abandoning a market or opportunity and taking on a <span epub:type="pagebreak" id="Page_108" role="doc-pagebreak" aria-label="108"/>fundamental, gut-wrenching level of change throughout its ethics, culture, processes, or people, for example. We see such choices almost before we’ve started to think about what the alternatives might cost and what they might gain us. These strategic choices are often used in combination to achieve the desired level of assurance against risk. As an SSCP, you’ll assist your organization in making these choices across strategic, tactical, and operational levels of planning, decision making, and actions that people and the organization must take. Note that each of these choices is a verb; these are things that you <i>do</i>, actions you perform. This is key to understanding which ones to choose and how to use them successfully. We’ll look at each individually, and then take a closer look at how they combine and mutually reinforce each other to attain greater protective effect.</p>&#13;
<p>There are choices at the strategic and tactical level that seem quite similar and are often mistaken as identical. The best way to keep them separate in your mind might be as follows:</p>&#13;
<ul class="square" id="c03-list-0039">&#13;
<li id="c03-li-0148">If you’ve just completed the risk assessment and BIA, your strategic choices are about <i>operational risk mitigation planning</i> and which risks to deal with in other ways. This is the strategic choice (as you’ll see) of deterring, detecting, preventing, or avoiding a risk altogether. Note that prevent, deter, and detect will probably involve choices of risk mitigation controls, but you cannot make those choices until after you’ve done the architectural and vulnerability assessments.</li>&#13;
<li id="c03-li-0149">If you’ve already done the architectural and vulnerability assessments, as we’ll cover in <a href="c04.xhtml">Chapter 4</a>, you’re ready to start making hard <i>mitigation</i> choices for the risks you’re not going to avoid altogether. These are <i>tactical</i> choices you’ll be making, as they will dictate how, when, and to what degree of completeness you implement operational (day-to-day), functional choices in the ways you try to control risks.</li>&#13;
</ul>&#13;
<p id="c03-para-0201">Having identified the risks and prioritized them, what next? What realistic options exist? One (more!) thing to keep in mind is that as you delve into the details of your architecture, and find, characterize, and assess its vulnerabilities against the prioritized set of risks, you will probably find some risks you thought you could and should “fix” that prove far too costly or disruptive to attempt to do so. <i>That’s okay</i>. Like any planning process, risk management and risk mitigation taken together are a living, breathing, dynamic set of activities. Let these assessments shed light on what you’ve already thought about, as well as what you haven’t seen before.</p>&#13;
<aside>&#13;
<div class="top hr"><hr/></div>&#13;
<section class="feature3" aria-labelledby="head-2-48"><span id="c03-fea-0010"/>&#13;
<h3 id="head-2-48">“Operational” or “Tactical” as the Day-to-Day?</h3>&#13;
<section><span id="c03-sec-0042"/>&#13;
<p id="c03-para-0202">What’s the right way to look at this hierarchy of broad, longer-term to fine-grain day-to-day detail? The definitions we’ve given you reflect how the <i>business</i> community speaks about planning and conducting business operations, with the smallest of day-to-day tasks as operations. Another way to think of this is to say that <i>tactics</i> transform strategies into processes you can use day by day to <i>operate</i> the business. If you’re familiar with military <span epub:type="pagebreak" id="Page_109" role="doc-pagebreak" aria-label="109"/>planning and operations, you’ll note that almost without exception, the world’s military thinkers, planners, and doctrine authors have flipped the roles of tactical and operational art and decision making. Operational art, for example, refers to the larger scale of maneuvering and positioning forces to achieve an objective, whereas tactics dictate how to train individual foot soldiers to lay down different patterns of small-arms fire in support of steps in that operational plan. Many agencies in the U.S. federal government, as well as those in Western Europe, also quite frequently talk tactics at the lowest level of this hierarchy of definitions.</p>&#13;
<p id="c03-para-0203">“The customer is always right” is perhaps the key to keep in mind. Usually you can tell from the context; when in doubt, ask!</p>&#13;
</section>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
<p id="c03-para-0204">So what are these strategic choices?</p>&#13;
<section><span id="c03-sec-0043"/>&#13;
<h3 id="head-3-44">Deter</h3>&#13;
<p id="c03-para-0205">To <i>deter</i> means to discourage or dissuade someone from taking an action because of their fear or dislike of the possible consequences. Deterring an attacker means that you get them to change their mind and choose to do something else instead. Your actions and your posture convince the attacker that what they stand to gain by launching the attack will probably not be worth the costs to them in time, resources, or other damages they might suffer (especially if they are caught by law enforcement!). Your actions do this by working on the attacker’s decision cycle. Why did they pick you as a target? What do they want to achieve? How probable is it that they can complete the attack and escape without being caught? What does it cost them to prepare for and conduct the attack? If you can cast sufficient doubt into the attacker’s mind on one or more of these questions, you may erode their confidence; at some point, the attacker gives up and chooses not to go through with their contemplated or planned attack.</p>&#13;
<p>By its nature, deterrence is directed onto an active, willful threat actor. Try as you might, you cannot deter an accident, nor can you command the tides not to flood your datacenter. You do have, however, many different ways of getting into the attacker’s decision cycle, demotivating them, and shaping their thinking so that they go elsewhere:</p>&#13;
<ul class="square" id="c03-list-0040">&#13;
<li id="c03-li-0150">Physical assets such as buildings (which probably contain or protect other kinds of assets) may have very secure and tamper-proof doors, windows, walls, or rooflines that prevent physical forced entry. Guard dogs, human guards or security patrols, fences, landscaping, and lighting can make it obvious that an attacker has very little chance to approach the building without being detected or prevented from carrying out their attack.</li>&#13;
<li id="c03-li-0151">Mandatory use of multi-factor authentication, along with strong passwords and other access control technologies, can make it visibly difficult for an attacker to hack into your computer systems (be they local or cloud-hosted).</li>&#13;
<li id="c03-li-0152">Policies and procedures can be used to train your people to make them less vulnerable to social-engineering attacks.</li>&#13;
</ul>&#13;
<p><span epub:type="pagebreak" id="Page_110" role="doc-pagebreak" aria-label="110"/>Deterrence can be passive, active, or a combination of the two. Fences, the design of parking, access roads and landscaping, and lighting tend to be passive deterrence measures; they don’t take actions in response to the presence of an attacker, for example. Active measures give the defender the opportunity to create doubt in the attacker’s mind: Is the guard looking my way? Is anybody watching those CCTV cameras?</p>&#13;
<aside>&#13;
<div class="top hr"><hr/></div>&#13;
<section class="feature3">&#13;
<p><img alt="Warning" src="Images/warning.png" class="left" width="91" height="53"/></p>&#13;
<p id="c03-para-0208">Active deterrence is <i>not</i> a counter-attack. Private organizations and nearly all government agencies would be in violation of the law to attempt to penetrate an attacker’s systems. The extremely rare instances of private companies being (in effect) deputized and thus authorized to perform take-down operations should not be emulated in your organization’s security operations.</p>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
</section>&#13;
<section><span id="c03-sec-0045"/>&#13;
<h3 id="head-3-45">Detect</h3>&#13;
<p id="c03-para-0209">To <i>detect</i> means to notice or consciously observe that an event of interest is happening. Notice the built-in limitation here: you have to <i>first</i> decide what set of events to “be on the lookout for” and therefore which events you possibly need to make action decisions about in real time. While you’re driving your car down a residential street, for example, you know you have to be watching for other cars, pedestrians, kids, dogs, and others darting out from between parked cars—but you normally would “tune out” watching the skies to see if an airplane was about to try to land on the street behind you. You also need to decide what to do about false alarms, both the false positives (that alarm when an event of interest hasn’t occurred) and the false negatives (the absence of an alarm when an event is actually happening).</p>&#13;
<p id="c03-para-0210">If you think of how many false alarms you hear every week from car alarms or residential burglar alarms in your neighborhood, you might ask why we bother to try to detect that an event of interest might possibly be happening. Fundamentally, you cannot respond to something if you do not know it is happening. Your response might be to prevent or disrupt the event, to limit or contain the damage being caused by it, or to call for help from emergency responders, law enforcement, or other response teams. You may also need to activate alternative operations plans so that your business is not severely disrupted by the event. Finally, you do need to know what actually happened so that you can decide what corrective actions (or remediation) to take—what you must do to repair what was damaged and to recover from the disruption the incident has caused.</p>&#13;
</section>&#13;
<section><span id="c03-sec-0046"/>&#13;
<h3 id="head-3-46">Prevent</h3>&#13;
<p id="c03-para-0211">To <i>prevent</i> an attack means to stop it from happening or, if it is already underway, to halt it in its tracks, thus limiting its damage. A thunderstorm might knock out your commercial <span epub:type="pagebreak" id="Page_111" role="doc-pagebreak" aria-label="111"/>electrical power (which is an <i>attack</i>, even if a nondeliberate one), but the uninterruptible power supplies keep your critical systems up and running. Heavy steel fire doors and multiple dead-bolt locks resist all but very determined attempts to cut, pry, or force an entry into your building. Strong access control policies and technologies prevent unauthorized users from logging into your computer systems. Fire-resistant construction of your home’s walls and doors is designed to increase the time you and your family have to detect the fire and get out safely before the fire spreads from its source to where you’re sleeping. (We in the computer trades owe the idea of a <i>firewall</i> to this pre-computer-era, centuries-old idea of keeping harm on one side of a barrier from spreading through to the other.)</p>&#13;
<p id="c03-para-0212">Preventive defense measures provide two immediate paybacks to the defender: they limit or contain damage to that which you are defending, and they cost the attacker time and effort to get past them. Combination locks, for example, are often rated in terms of how long it would take someone to just “play with the dial” to guess the combination or somehow sense that they’ve started to make good guesses at it. Fireproof construction standards aim to prevent the fire from burning through (or initiating a fire inside the protected space through heat transfer) for a desired amount of time.</p>&#13;
<p id="c03-para-0213">Note that we gain these benefits whether we are dealing with a natural, nonintentional threat, an accident, or a deliberate, intentional attack.</p>&#13;
</section>&#13;
<section><span id="c03-sec-0047"/>&#13;
<h3 id="head-3-47">Avoid</h3>&#13;
<p>To <i>avoid</i> an attack means to change what you do, and how you do it, in such ways as to not be where your attacker is expecting you to be when they try to attack you. This can be a temporary change to your planned activities or a permanent change to your operations. In this way, you can reduce or eliminate the possible disruptions or damages of an attack from natural, accidental, or deliberate causes:</p>&#13;
<ul class="square" id="c03-list-0041">&#13;
<li id="c03-li-0153">Physically avoiding an attack might involve relocating part of your business or its assets to other locations, shutting down a location during times of extremely bad weather, or even closing a branch location that’s in too dangerous a market or location.</li>&#13;
<li id="c03-li-0154">Logically avoiding an attack can be done by using cloud service providers to eliminate your business’s dependence on a specific computer system or set of services in a particular place. At a smaller scale, you do this by making sure that the software, data, and communications systems allow your employees to get business done from any location or while traveling, without regard to where the data and software are hosted. Using a virtual private network (VPN) to mask your IP and Media Access Control (MAC) addresses is another example of using logical means to avoid the possible consequences of an attack on your IT infrastructure and information systems.</li>&#13;
<li id="c03-li-0155">A variety of administrative methods can be used, usually in conjunction with physical or logical ones such as those we’ve discussed. Typically they will be implemented in policies, procedural documents, and quite possibly contracts or other written agreements.</li>&#13;
</ul>&#13;
<span epub:type="pagebreak" id="Page_112" role="doc-pagebreak" aria-label="112"/>&#13;
<aside>&#13;
<div class="top hr"><hr/></div>&#13;
<section class="feature3" aria-labelledby="head-2-49"><span id="c03-fea-0011"/>&#13;
<h3 id="head-2-49">Ignoring or Accepting a Risk</h3>&#13;
<section><span id="c03-sec-0048"/>&#13;
<p id="c03-para-0216">One additional choice is available to you as a risk manager: choose to ignore or accept a risk and its possible consequences. This is not strictly a “risk treatment” option, since it does nothing to reduce the possible impact or loss if the risk should occur. However, it does allow you to decide that in some specific cases, the cost of not pursuing the goal or objective because of that risk is just too much of an <i>opportunity cost</i> to bear. Consider the collision damage insurance on your personal car, for example. At some point in time, the premiums you pay to cover the possibility of damage to your car in an accident exceed the actual market value of your car—you pay more to insure it than your insurer will pay to repair it, even if the car is “totaled” or damaged beyond repair. So, by becoming <i>self-insuring</i> for collision damage, you accept the risk (or choose to ignore its possibilities) when you stop paying collision damage premiums, sign a waiver of coverage with your insurer, and use the money you save for some other opportunity.</p>&#13;
</section>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
<p>Like everything in risk management and risk mitigation, these basic elements of choice can be combined in a wide variety of ways:</p>&#13;
<ul class="square" id="c03-list-0042">&#13;
<li id="c03-li-0156">Alarms combine detection and notification to users and systems owners; by alerting the attacker that they’ve been spotted “in the act,” the sound of the alarms may motivate the attacker to stop the attack and leave the scene (which is a combination of preventing further damage while it deters and prevents continued or repeated attack).</li>&#13;
<li id="c03-li-0157">Strong protective systems can limit or contain damage during an attack, which prevents the attack from spreading; to the degree that these protective systems are visible to the attacker, they may also deter the attack by raising the costs to the attacker to commence or continue the attack. They may also raise the attacker’s fear of capture, arrest, or other losses and thus further deter attack.</li>&#13;
<li id="c03-li-0158">Most physical and logical attack avoidance methods require a solid policy and procedural framework, and they quite often require users and staff members to be familiar with them and even trained in their operational use.</li>&#13;
</ul>&#13;
<p id="c03-para-0218">This last point bears some further emphasis. Organizations will often spend substantial amounts of money, time, and effort to put physical and even logical risk management systems into use, only to then put minimal effort into properly defining the who, what, when, where, how, and why of their use, maintenance, and ongoing monitoring. The money spent on a strong, imposing fence around your property will ultimately go to waste without routinely inspecting it and keeping it maintained. (Has part of it been knocked down by frost heave or a fallen tree? Has someone cut an opening in it? You’ll never know if you don’t walk the fence line often.)</p>&#13;
<p id="c03-para-0219">This suggests that <i>continuous follow-through</i> is in fact the weakest link in our information risk management and mitigation efforts. We’ll look at ways to improve on this in the remainder of this book.</p>&#13;
<span epub:type="pagebreak" id="Page_113" role="doc-pagebreak" aria-label="113"/>&#13;
<aside>&#13;
<div class="top hr"><hr/></div>&#13;
<section class="feature3" aria-labelledby="head-2-50"><span id="c03-fea-0012"/>&#13;
<h3 id="head-2-50">Defending Your Bank Accounts at the ATM</h3>&#13;
<section><span id="c03-sec-0049"/>&#13;
<p>As a retail (consumer) bank customer, you typically can withdraw or deposit money into your bank account in one of several ways. Deposits can be done by postal mail, at an ATM, by online deposit of a check, or by transfer from another account (yours or someone else’s). Withdrawals can be done by writing a check, using a debit or credit card for a purchase, withdrawing cash at an ATM, or doing a transfer to another account. As a retail customer, you expect your bank to:</p>&#13;
<ul class="square" id="c03-list-0043">&#13;
<li id="c03-li-0159">Detect all attempts to access your bank accounts, and information about you and your accounts at the bank.</li>&#13;
<li id="c03-li-0160">Notify you immediately of any attempts that seem unauthorized. Keep records of all attempts, whether successful or not, to access your accounts and bank information.</li>&#13;
<li id="c03-li-0161">Prevent any unauthorized transfers of funds into or out of your accounts.</li>&#13;
</ul>&#13;
<p id="c03-para-0221">Note that you don’t really expect your bank to <i>avoid</i> unauthorized attempts to access your accounts or withdraw funds; you expect it to <i>prevent</i> them. (Why would that make sense to you?)</p>&#13;
<p>Let’s look more closely at one aspect of your relationship with your bank: account access via an ATM. To fulfill its due diligence responsibilities, the bank must ensure that the ATM is installed, maintained, protected, and monitored, perhaps by requiring that</p>&#13;
<ul class="square" id="c03-list-0044">&#13;
<li id="c03-li-0162">All of its ATMs are in well-lighted, indoor areas, with sufficient surveillance to make it very unlikely that a threat actor could attach card skimmers, micro-cameras, or similar devices in an attempt to capture your card information, PIN, etc.</li>&#13;
<li id="c03-li-0163">Surveillance of its ATMs is visible and obvious, making it seem unlikely that someone could assault a customer during or after they do an ATM transaction.</li>&#13;
<li id="c03-li-0164">The ATM machines themselves, and their communications links, are physically and logically protected so as to make it difficult, time-consuming, and costly for an attacker to gain access to the ATM control mechanisms, customer data, transaction data, or cash in the machine.</li>&#13;
</ul>&#13;
<p id="c03-para-0223">Would you expect or require anything else from your bank?</p>&#13;
<p id="c03-para-0224">Which of your expectations (or requirements) are part of the bank’s due care responsibilities? Which are part of its due diligence responsibilities?</p>&#13;
<p id="c03-para-0225">Let’s go a step further into the real world. This is all well and good for ATMs that the bank owns or operates under contract, but what about network ATMs, possibly located around the world, operated and maintained by many different companies in many different legal jurisdictions?</p>&#13;
</section>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
</section>&#13;
</section>&#13;
<section aria-labelledby="head-2-51"><span id="c03-sec-0050"/>&#13;
<h2 id="head-2-51"><span epub:type="pagebreak" id="Page_114" role="doc-pagebreak" aria-label="114"/>Summary</h2>&#13;
<p id="c03-para-0226">Every organization, large or small, public or private, faces an almost limitless sea of risks—things that can go wrong or at least occur in unanticipated ways. Risk management is about the possibilities of future events upsetting or disrupting our plans of today, and the systems and business processes we use today. At its heart, risk management is about ensuring that decisions can be made reliably, on time, and on target; thus we see that information security is really about delivering decision assurance; it’s about increasing our confidence that the decisions we make (large or small) are ones we can count on.</p>&#13;
<p id="c03-para-0227">Risk management is the responsibility of the organization’s leaders and stakeholders; they have the primary burdens of due care (to ensure that they’re doing business correctly and effectively) and of due diligence (to continuously monitor and assess how well their business is working and whether it could work <i>better</i>). Since we cannot address every risk, and in fact cannot usually address any specific risk perfectly and completely, we’ve seen that risk management is the art of compromise. As SSCPs, we must balance the organization’s tolerance for risk against its ability and willingness to spend money, time, effort, and other assets to contain, control, or limit the impacts those risks might have if they actually occur.</p>&#13;
<p id="c03-para-0228">Risk management frameworks can provide us the managerial structures and the organized knowledge of experience that we need to plan and conduct our risk management and mitigation activities. If risk management is making decisions about risk, risk mitigation is carrying out those decisions.</p>&#13;
<p id="c03-para-0229">The interplay between management and mitigation, between decision making and implementation, is continuous. We can, however, see that some actions and decisions are strategic, affecting the very survival or long-term success of the organization. Many others are directly involved in day-to-day business operations; and in between, tactical decisions, plans, and actions translate strategic needs and decisions into the world of the day to day.</p>&#13;
<p id="c03-para-0230">The bridge between risk management and risk mitigation is the BIA, the business impact analysis. This analysis combines the organizational priorities and an in-depth understanding of business processes, along with their vulnerabilities. In doing so, it provides the starting point for the next set of hard work: implementing, testing, and operationally using the right set of risk mitigation controls, which we’ll explore in <a href="c04.xhtml">Chapter 4</a>.</p>&#13;
</section>&#13;
<section aria-labelledby="head-2-52"><span id="c03-sec-0051"/>&#13;
<h2 id="head-2-52">Exam Essentials</h2>&#13;
<ul class="none" id="c03-list-0045">&#13;
<li id="c03-li-0165"><b>Explain the information risk management process</b>.  Information risk management is a process that guides organizations through identifying risks to their information, information systems, and information technology systems; characterizing those risks in terms of impacts to prioritized goals and objectives; making decisions about which risks to treat, accept, transfer, or ignore; and then implementing risk treatment plans. As an ongoing management effort, it requires continuous monitoring of internal systems and processes, as well as constant awareness of how threats and vulnerabilities are evolving throughout the world.&#13;
<p><span epub:type="pagebreak" id="Page_115" role="doc-pagebreak" aria-label="115"/><b>Explain information risk and its relationship to information systems and decision making.</b>  You need information to make any decision, and if you cannot trust in that information’s confidentiality, integrity, and availability when you must make a decision, then your decision is at risk. Information systems implement the processes that gather data, process it, and help you generate new information; risks that cause these processes to suffer a compromise of confidentiality, integrity, or availability are thus information systems risks. These information systems risks further reduce your confidence that you can make on-time, accurate decisions.</p>&#13;
<p id="c03-para-0234" class="listPara1"><b>Differentiate between outcomes-based, process-based, asset-based, and threat-based views of risk.</b>  Each of these provides alternative ways to view, think about, or assess risks to an organization, and they apply equally to information risks or any other kind of risk. Outcomes-based starts with goals and objectives and what kind of risks can impact your ability to achieve them. Process-based looks at your business processes and how different risks can impact, disrupt, or block your ability to run those processes successfully and correctly. Asset-based risks looks at any tangible asset (hardware, machinery, buildings, people) or intangible asset (knowledge, business know-how, or information of any kind) and asks how risks can decrease the value of the asset or make it lose usefulness to the business. Threat-based, also called vulnerability-based, focuses on how things go wrong—what the root and proximate causes of risks might be—whether natural, accidental, or deliberately caused. Note that <i>threats</i> are intentional acts committed (or contemplated) by humans and human organizations, while <i>hazards</i> are caused by natural events, accidents, or failure due to wear and tear.</p>&#13;
<p id="c03-para-0235" class="listPara1"><b>Explain why information risk management needs to be integrated and proactive.</b>  Information security managers and incident responders need to know the status, state, and health of all elements of the information system, including its risk controls or countermeasures, in order to make decisions about dealing with an <i>incident of interest</i>. The timeliness and integrity of this information is critical to detecting an incident, characterizing it, and containing it before it causes widespread damage or disruption. Integrating all elements of your information risk management systems brings this information together rapidly and effectively to enable timely incident management. To be proactive requires that you think ahead to possible outcomes of risk events, and devise ways to deter, detect, prevent, contain, or avoid the impacts of such events, rather than merely being reactive—waiting until an event happens to learn from it, and only then instituting risk controls for the <i>next</i> time such an event occurs.</p>&#13;
<p id="c03-para-0237" class="listPara1"><b>Differentiate due care from due diligence for information risk management.</b>  Due care and due diligence both aim to strike a prudent, sensible balance between “too little” and “too much” when it comes to implementing any set of responsibilities. Due care requires identifying information risks to high-priority goals, objectives, processes, or assets; implementing controls, countermeasures, or strategies to limit their possible impacts; and operating those controls (and the systems themselves) in prudent and responsible ways. Due diligence requires ongoing monitoring of these controls as well as periodic verification that they still work correctly and that new vulnerabilities or threats, changes in business needs, or changes in the underlying systems have not broken some of these risk control measures.</p>&#13;
<p id="c03-para-0238" class="listPara1"><span epub:type="pagebreak" id="Page_116" role="doc-pagebreak" aria-label="116"/><b>Know how to conduct an information risk assessment.</b>  Start with a prioritized list of outcomes, processes, assets, threats, or a mix of these; it is important to know that you’re assessing possible risks in decreasing order of their importance or concern to leadership and management. The next step is to gather data to help make quantitative and qualitative assessments of the impact of each risk to the organization and its information, should such a risk event occur. Data from common vulnerabilities and exploitations registries (national and international) can assist by pointing out things to look for. As part of this, build a risk registry, a database or listing of the risks you have identified, your impact assessments, and what you’ve learned about them during your investigation. This combined set of information feeds into the BIA process.</p>&#13;
<p id="c03-para-0239" class="listPara1"><b>Know what a business impact analysis is, and explain its role in information risk management.</b>  The BIA brings together everything that has been learned in the information risk assessment process and organizes it in priority order, typically by impact (largest to smallest, soonest versus later in time, highest-priority business objective, etc.). It combines quantitative and qualitative assessments to characterize the impacts these risks might cause if they became incidents. Typically, the BIA will combine risk perspectives so that it characterizes the impacts of a risk to high-interest goals and objectives as well as to costs, revenues, schedules, goodwill, or other stakeholder interests.</p>&#13;
<p id="c03-para-0240" class="listPara1"><b>Know the role of a risk register in information risk management.</b>  A risk register is a document, database, or other knowledge management system that brings together everything the organization learns about risks, as it’s learned. Ideally it is organized in ways that capture analysis results, management decisions, and updates as controls and countermeasures are implemented and put to use. Like the BIA, it should be a living document or database.</p>&#13;
<p id="c03-para-0241" class="listPara1"><b>Know the difference between qualitative and quantitative assessments and their use.</b>  Quantitative assessments attempt to arithmetically compute values for the probability of occurrence and the single loss expectancy. These assessments typically need significant insight into costs, revenues, usage rates, and many other factors that can help estimate lost opportunities, for example. Qualitative assessments, by contrast, depend on experienced people to judge the level or extensiveness of a potential impact, as well as its frequency of occurrence. Both are valuable and provide important insight; quite often, management and leadership will believe they do not have sufficient data to support a quantitative assessment, or enough knowledge and wisdom in an area of operations to make a qualitative judgment.</p>&#13;
<p id="c03-para-0243" class="listPara1"><b>Know how to calculate the key elements of a quantitative risk assessment.</b>  The single loss expectancy (SLE) is the total of all losses that could be incurred as a result of one occurrence of a risk. Typically expressed in monetary terms, it includes repair and restoration costs for hardware, software, facilities, data, people, loss of customer goodwill, lost business opportunity, or other costs directly attributable to the event. The annual rate of occurrence (ARO) is an estimate of how many times per year a particular risk is considered likely to occur. An ARO of 0.5, for example, says that this risk is expected to occur no more often than once every two years. The annual loss expectancy (ALE) is the product of the SLE multiplied by the ARO, and it represents the yearly expected losses because of this one risk.</p>&#13;
<p id="c03-para-0244" class="listPara1"><span epub:type="pagebreak" id="Page_117" role="doc-pagebreak" aria-label="117"/><b>Know how to determine the safeguard value.</b>  The safeguard value is the total cost that may be incurred to specify or design, acquire, install, operate, and maintain a specific risk mitigation control or countermeasure. You need to first complete vulnerabilities assessments in order to know what to fix, control, or counter, however.</p>&#13;
<p id="c03-para-0245" class="listPara1"><b>Explain what MAO, RTO, and RPO mean.</b>  The maximum acceptable outage (MAO) is the time limit to restore all mission-essential systems and services so as to avoid impact to the mission of the organization. Recovery time objectives (RTOs) are established for each system that supports the organization and its missions. Organizations may set more aggressive needs for recovery, and if so, they may be spending more than is necessary to achieve these shorter RTOs. All RTOs must be shorter than the MAO that they support; otherwise, the MAO cannot be achieved. Recovery point objectives (RPOs) relate to the maximum data loss that the organization can tolerate because of a risk event; they can be expressed as numbers of transactions or in units of time. Either way, the RPO represents work that has to be accomplished again, and is paced by what sort of backup and restore capabilities are in place.</p>&#13;
<p id="c03-para-0246" class="listPara1"><b>Explain threat modeling and its use in information risk assessment.</b>  Threat modeling starts with the premise that all systems have an external boundary that separates what the system owner, builder, and user own, control, or use, from what’s not part of the system (that is, the rest of the world and the Internet). Systems are built by putting together other systems or elements, each of which has its boundary. Thus, there are internal boundaries inside every system. Crossing any boundary is an opportunity to ask security-driven questions—whether this attempt is authorized, for an authorized purpose, at this time, for example. The external boundary of a system is thus called its threat surface, and as you identify every way that something or someone can cross a boundary, you are identifying, characterizing, and learning about (modeling) the threats with respect to that surface. The outermost threat surface can (and should) be known without needing to delve into system internal design and construction, but the real payoff is when, layer by layer, these boundaries are examined for possible trapdoors, Trojan horse “features,” or other easily exploitable weaknesses.</p>&#13;
<p id="c03-para-0247" class="listPara1"><b>Know the basic choices for limiting or containing damage from risks.</b>  The choices are deter, detect, prevent, and avoid. Deter means to convince the attacker that costs they’d incur and difficulties they’d encounter by doing an attack are probably far greater than anticipated gains. Detecting that an attack is imminent or actually occurring is vital to taking any corrective, evasive, or containment actions. Prevention either keeps an attack from happening or contains it so that it cannot progress further into the target’s systems. Avoiding the possible damage from a risk requires terminating the activity that incurs the risk, or redesigning or relocating the activity to nullify the risk.</p>&#13;
<p id="c03-para-0248" class="listPara1"><b>Know what a risk management framework is and what organizations can gain by using one or tailoring one to their needs.</b>  Risk management frameworks (RMFs) are compendiums of guidance based on experience in identifying, characterizing, managing, and mitigating risks to public and private organizations. RMFs, typically, are created by government agencies or international standards organizations, and they may be directive or advisory for an organization depending on the kind of business it’s in. RMFs provide rich sets of management processes that you can select from and tailor to the needs of your particular business.</p>&#13;
<p id="c03-para-0249" class="listPara1"><span epub:type="pagebreak" id="Page_118" role="doc-pagebreak" aria-label="118"/><b>Explain the role of organizational culture and context in risk management.</b>  Organizations have their own “group personalities,” which may or may not resemble those of their founders or current senior leaders, managers, or stakeholders. How decisions get made, whether quantitative assessments are preferred (or not) over qualitative ones, and how the appetite for risk is determined are just some of the key elements of culture that set the context for information risk management planning and implementation.</p>&#13;
<p id="c03-para-0250" class="listPara1"><b>Describe the basic steps of the NIST Special Publication 800-37 Rev. 2 RMF.</b>  This RMF describes seven major steps to information and privacy risk management: Prepare, Categorize, Select, Implement, Assess, Authorize, and Monitor. As these names, expressed as verbs, suggest, the actions that organizational leadership, management, and security or risk management specialists should take start at the broad cultural or context level, move through understanding information risk impacts, and choose, build, install, and activate new risk controls or countermeasures. Once activated, these controls are assessed for effectiveness, and senior leadership then declares them part of the new operational baseline. Ongoing monitoring ensures due diligence.</p>&#13;
<p id="c03-para-0251" class="listPara1"><b>Explain what a zero day exploit means.</b>  A zero day exploit involves a vulnerability discovered but not reported to the affected system’s builders, vendors, or users, or the information security community at large. Between the time of its discovery and such reporting and notification, attackers who know of the vulnerability can create an exploit with which they can attack systems affected by that vulnerability. The term suggests that the system’s defenders have zero time to prepare for such an exploit, since they are not aware of the vulnerability or the potential for an attack based on it.</p>&#13;
<p id="c03-para-0253" class="listPara1"><b>Differentiate a hazard from a threat.</b>  Accidents and risk events that occur because of natural causes such as weather or earthquakes are known as <i>hazards</i> by insurance and risk managers. These are <i>unintentional events</i>—weather and Nature are not conscious actors that can decide to cause damage to occur. By contrast, a <i>threat</i> is an action that is taken by (or contemplated to be taken) by a human being or a human organization. It is <i>intentional</i>; a conscious decision is made to attempt to achieve an outcome or result by making the risk event become reality. These humans are known as <i>threat actors</i> in risk management and security terms.</p>&#13;
<p id="c03-para-0254" class="listPara1"><b>Differentiate a security classification from a security categorization.</b>  <i>Security classification</i> is the process of identifying or estimating the possible impacts or losses an organization might suffer if information of a particular type is compromised. This compromise can relate to its confidentiality, integrity, availability, nonrepudiability, authenticity, privacy, or safety characteristics. Laws, regulations, standards, or contracts which establish compliance requirements for protecting sensitive information, combined with business impact assessments, provide the basis for developing a set of information security classification policies, procedures, and labels. <i>Security categorization</i> is a process which groups together sets of information that have comparable security classification and security protection needs or requirements. Categorization allows for more optimal planning and operation of security processes, and avoids the expense and risks associated with a one-size-fits-all approach that treats all data as if it is classified at the most secure level.</p>&#13;
<p id="c03-para-0255" class="listPara1"><span epub:type="pagebreak" id="Page_119" role="doc-pagebreak" aria-label="119"/><b>Explain how classification and categorization relate to a security baseline.</b>  A <i>security baseline</i> is a matrix or table that relates data sets or types based on their classification, categorization, and required or chosen minimum essential security protection methods. This enables security planners to quickly determine which information types (by classification and category) might be put at risk when a protection method, such as an encryption or access control technology, has been shown to be no longer as secure as the organization requires it to be.</p></li>&#13;
</ul>&#13;
</section>&#13;
<section aria-labelledby="head-2-53"><span id="c03-sec-0052"/>&#13;
<h2 id="head-2-53"><span epub:type="pagebreak" id="Page_120" role="doc-pagebreak" aria-label="120"/>Review Questions</h2>&#13;
<section><span id="c03-exsec-0001"/>&#13;
<ol>&#13;
<li id="c03-ex-0001">Which of the following shows the major steps of the information risk management process in the correct order?&#13;
<ol class="upper-alpha">&#13;
<li>Assess risks across the organization; identify information security and privacy risks; implement countermeasures; establish security and privacy posture; review supply chain for IT security risk elements</li>&#13;
<li>Establish basic security posture; review risks; implement countermeasures; perform ongoing monitoring and assessment, testing, and training</li>&#13;
<li>Set priorities; assess risks; select controls and countermeasures; implement controls; validate correct operation; monitor</li>&#13;
<li>Develop business impact analysis; establish risk tolerance levels; implement damage control choices; monitor</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0002">What is information risk?&#13;
<ol class="upper-alpha">&#13;
<li>The threat that data on your computers, online storage, local or cloud-hosted data, or other data could be hacked into, stolen, or changed</li>&#13;
<li>The probability of an event occurring that disrupts your information and the business processes and systems that use it</li>&#13;
<li>Vulnerabilities in your information systems that can be exploited by a threat actor and cause harmful impacts</li>&#13;
<li>The probability that management’s and leadership’s directions and communications will be misunderstood, causing the wrong actions to be taken by stakeholders, possibly causing financial loss, injury, or death</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0003">How does information risk relate to information systems risk or information technology risk?&#13;
<ol class="upper-alpha">&#13;
<li>These three terms all mean much the same thing, although with a greater or lesser degree of emphasis on securing the underlying computers and networks.</li>&#13;
<li>They express the logical flow of making decisions about risk: first, what information do you need; second, how you get it, use it, and share it with others in the decision process; and third, what technologies help make all of that happen. The probability of an event causing a disruption to any step of that decision process is a risk.</li>&#13;
<li>They reflect the need to think about risks in outcomes-based, process-based, asset-based, or threat-based terms.</li>&#13;
<li>They suggest the levels of organizational leadership and management that need to be part of managing each risk: senior leaders with information risk, tactical unit managers with information systems risks, and the IT department with information technology risks.</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0004"><span epub:type="pagebreak" id="Page_121" role="doc-pagebreak" aria-label="121"/>Which statement about risk perspectives or views is most correct?&#13;
<ol class="upper-alpha">&#13;
<li>Outcomes-based risk assessment is best, because it focuses attention on the highest-priority goals and objectives of the organization as the places to start risk identification and assessment.</li>&#13;
<li>Asset-based risk assessment is best, because it focuses attention on where your sunk costs or remaining book value of capital assets is greatest, and thus most expensive to repair or replace if a risk occurs.</li>&#13;
<li>Threat-based risk management is best, because it keeps you looking at rapidly evolving exploits and forces you to realize that somebody, somewhere, has their own reasons for stealing every stray bit of information or computer power from you.</li>&#13;
<li>Each of these provides great insight as you start your risk management planning and implementation efforts; no one approach by itself covers everything a good risk management strategy must do.</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0005">What does it mean to have an integrated information risk management system?&#13;
<ol class="upper-alpha">&#13;
<li>You choose controls and countermeasures that provide all-risk coverage, have graceful degradation or fallback capabilities, and provide end-to-end visibility and management via built-in command, control, and communications capabilities.</li>&#13;
<li>You avoid point defense countermeasures or controls, as they tend to make you overlook gaps between them.</li>&#13;
<li>You provide the communications capabilities to bring status, state, and health information from all countermeasures and controls, and all systems elements, to information security managers, who can then direct timely changes in these controls in real time as required to respond to an incident.</li>&#13;
<li>Vendors of security information and event managers claim that their products are “integrated,” but they often do not clearly say what this means or help customers achieve greater security because of this.</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0006">Which is the most correct statement as to what it means to have a proactive approach with your information security risk management plans, programs, and systems?&#13;
<ol class="upper-alpha">&#13;
<li>Being proactive means that your countermeasures and controls can actively trace back to identify, locate, and characterize your attackers, which can help you both in defending against them and in potentially seeking legal redress.</li>&#13;
<li>Senior leaders and managers in many businesses appreciate active, thoughtful, forward-looking approaches, and you will find it easier to gain their support.</li>&#13;
<li>Proactive information security systems allow your security specialists to take real-time control of all system elements, and bring all information about events of interest into one common operational picture. This greatly enhances your ability to detect, characterize, and contain incidents.</li>&#13;
<li>Being proactive means that you use the best knowledge you have today, including lessons learned from other organizations’ experience with information risk, and you plan ahead to deal with them, rather than wait for them to occur and then investigate how to respond to them.</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0007"><span epub:type="pagebreak" id="Page_122" role="doc-pagebreak" aria-label="122"/>Tom is the chief information security officer for a medium-sized business. It’s been brought to his attention that the company has been storing its backup systems images and database backups in an offsite facility that has no alarm system and no way of knowing whether there were any unauthorized persons entering that facility. Which of the following might apply to this situation?&#13;
<ol class="upper-alpha">&#13;
<li>This could be a failure of due care in that security requirements for the backup information should have been specified and implemented in the storage plan and contracts.</li>&#13;
<li>Since there are no records to check to see if any unauthorized persons had access to these backups, there has been no due diligence lapse.</li>&#13;
<li>This is at least a failure of due diligence, since there seems to have been no systematic or periodic check of the storage facility or the backup media stored in it.</li>&#13;
<li>This could be a case of failing to perform both due care and due diligence.</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0008">What kind of information is part of an information risk assessment process? (Choose all that apply.)&#13;
<ol class="upper-alpha">&#13;
<li>Lost revenues during the downtime caused by the risk incident, including the time it takes to get things back to normal</li>&#13;
<li>Damage to equipment or facilities, or injury or death to people</li>&#13;
<li>Estimated costs to implement chosen solutions, remediations, controls, or countermeasures</li>&#13;
<li>Total costs to create an asset that is damaged or disrupted by the risk event</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0009">The acronym BIA refers to which of the following?&#13;
<ol class="upper-alpha">&#13;
<li>A document identifying all of the impacts to the business due to the risks it has chosen to assess; forms the basis for risk mitigation planning and implementation</li>&#13;
<li>The basic information security needs to provide for the privacy, integrity, and availability of business information</li>&#13;
<li>The budgeted implementation and accreditation plan for information security, often required by insurers and financial authorities of businesses dealing with sensitive or safety-related information</li>&#13;
<li>The budgeted cost of information availability, which when compared with the actual cost of information availability, lets management assess planned versus actual success of their information risk management programs</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0010">There are three ways in which risk assessments can be done. Choose the answer that orders them from best to least in terms of their contribution to risk management decision making.&#13;
<ol class="upper-alpha">&#13;
<li>Qualitative, quantitative, and CVE-based</li>&#13;
<li>CVE-based, quantitative, and qualitative</li>&#13;
<li>There is no order; they all can and should be used, as each reveals something more about the risks you have to manage.</li>&#13;
<li>Quantitative, CVE-based, and qualitative</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0011"><span epub:type="pagebreak" id="Page_123" role="doc-pagebreak" aria-label="123"/>Terri has recently been assigned to the information security team as a risk assessment analyst. As she goes through the files (on paper and in the company’s cloud-based information systems) that the company already has, she realizes that they are inconsistent in format and hard to use to perform analysis, and that there are no controls over who in the company can access these files. Does any of this present an information security concern? (Choose all that apply.)&#13;
<ol class="upper-alpha">&#13;
<li>No, because the company would have chosen a cloud systems provider that fully protects any unauthorized persons or outsiders from accessing any company data.</li>&#13;
<li>Yes, because the data in these files could represent significant vulnerabilities of company systems, and its inadvertent or deliberate disclosure could be very damaging to the company.</li>&#13;
<li>Yes, because the lack of controls on access and use suggests that data integrity is lacking or cannot be assessed.</li>&#13;
<li>Yes, because conflicting formats and content might make much of the data unusable for analysis and decision making without a lot of effort, impacting whether that data can support decision making in a timely manner.</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0012">Patsy is reviewing the quantitative risk assessment spreadsheet for her division, and she sees a number of entries where the annual loss expectancy is far greater than the single loss expectancy. This suggests that:&#13;
<ol class="upper-alpha">&#13;
<li>The RTO is later than the RPO.</li>&#13;
<li>The ARO is less than 1.</li>&#13;
<li>The particular risk is assessed to happen many times per year; thus its ARO is much greater than 1.0.</li>&#13;
<li>This looks like an error in estimation or assessment, and it should be further investigated.</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0013">How do you use RTO, MAO, and RPO in planning information risk management activities? Select the statements that are correct.&#13;
<ol class="upper-alpha">&#13;
<li>Return to operations (RTO) is the desired time to get all business processes back into operation, whether on backup or workaround systems or on production systems. The recovery point objective (RPO) sets priorities for which systems to bring up first, or for which business processes to get back into operation before others (of lower priority).</li>&#13;
<li>The recovery point objective (RPO) establishes the maximum amount of data that is lost due to a risk event. This could be in numbers of transactions or in units of time, and it indicates the amount of rework of information that is acceptable to get systems back into normal operation.</li>&#13;
<li>The recovery time objective (RTO) must be less than or equal to the maximum acceptable outage. The MAO sets a maximum downtime (outage time) before mission impact becomes unacceptable; the RTO can be used to emphasize faster than MAO restoration.</li>&#13;
<li>The maximum acceptable outage (MAO) relates to the mission or business objectives; if multiple systems support those objectives, then all of their recovery time objectives (RTOs) must be less than or equal to the MAO.</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0014"><span epub:type="pagebreak" id="Page_124" role="doc-pagebreak" aria-label="124"/>Threat modeling and threat assessment:&#13;
<ol class="upper-alpha">&#13;
<li>Should be done during risk management so that the threat modeling and assessment can drive the detailed work of risk mitigation planning</li>&#13;
<li>Refer to the boundaries of a system and look to identify, understand, assess, and manage anything that attempts to cross that boundary as a way to identify possible threats</li>&#13;
<li>Involves highly mathematical approaches, such as predictive code analysis, to produce meaningful results</li>&#13;
<li>Is best done using modeling and simulation tools</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0015">What are all of the choices you need to make when considering information risk management, and what’s the correct order to do them in?&#13;
<ol class="decimal">&#13;
<li>Treatment: accept, treat (fix or mitigate), transfer, avoid, recast</li>&#13;
<li>Damage limitation: deter, detect, prevent, avoid</li>&#13;
<li>Perspective: outcomes, assets, process or threat based</li>&#13;
<li>Impact assessment: quantitative or qualitative</li>&#13;
</ol>&#13;
<ol class="upper-alpha">&#13;
<li>1, 2, 3, then 4</li>&#13;
<li>3, 4, 2, then 1</li>&#13;
<li>4, 3, 2, then 1</li>&#13;
<li>2, 3, 1 then 4</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0016">Jill has recently joined a software development startup company as an information risk analyst, and she notices that the company does not make use of any risk management frameworks. Which is the best advice you could give to Jill?&#13;
<ol class="upper-alpha">&#13;
<li>As a new employee, she’d be speaking out of turn to say anything just yet. Watch and learn.</li>&#13;
<li>As an SSCP, Jill knows that risk management frameworks can offer valuable lessons to learn from as organizations start to plan and conduct risk management (and information risk management) activities. Jill should talk with her supervisor, and perhaps propose that she draft a concept for how to select, tailor, and use one of the widely accepted RMFs.</li>&#13;
<li>Jill should suggest to her supervisor that key stakeholders, perhaps even the board of directors, would not be pleased to see that the company is “reinventing this wheel” on its own. Perhaps the organization should adapt an RMF to its needs, she suggests.</li>&#13;
<li>Most RMFs really do not add value to small, entrepreneurial firms just starting out. Jill can keep the use of RMFs in the back of her mind, and maybe find small elements of these large, complex frameworks to introduce, bit by bit, to her company’s security processes and posture.</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0017">Why do SSCPs need to appreciate the culture of the organization they are working with in order to be effective as information risk managers? (Choose all that apply.)&#13;
<ol class="upper-alpha">&#13;
<li>Organizational culture determines how willingly managers and workers at all levels will accept greater responsibilities and accountability, which can severely limit the SSCP’s ability to get a risk management plan enacted.</li>&#13;
<li>“Old-boy” networks and informal information and decision paths may make anything written down in business processes, manuals, and so forth somewhat suspect.</li>&#13;
<li><span epub:type="pagebreak" id="Page_125" role="doc-pagebreak" aria-label="125"/>Privately held companies tend to be run more loosely than publicly held ones, because shareholder protection law and regulations dictate limits on what executives and board members can do or how they can do it.</li>&#13;
<li>Larger companies have probably had more different people in key positions over time, and so the effect of one domineering personality (as might happen in small entrepreneurial organizations) is probably not as pronounced.</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0018">As chief risk officer, you are asked if ignoring a risk is the same thing as accepting it. Which of the following might be part(s) of your reply?&#13;
<ol class="upper-alpha">&#13;
<li>Yes, because in both cases you have decided to do nothing different and just keep on with business as usual.</li>&#13;
<li>No, because quite often you choose to ignore something without first really understanding it or assessing its possible impacts to you.</li>&#13;
<li>No, because in ignoring a risk you may be violating your own responsibilities for due care or due diligence.</li>&#13;
<li>Yes, because as the responsible manager, you still have due care and due diligence responsibilities here.</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0019">When we call an attack a “zero day exploit,” we mean that:&#13;
<ol class="upper-alpha">&#13;
<li>The attack exploited a vulnerability within the first 24 hours of its discovery.</li>&#13;
<li>The attack exploited a vulnerability within the first 24 hours of its being announced by the affected systems or software vendor, or when it was posted in the CVE.</li>&#13;
<li>This term is meaningless hyperbole, invented by the popular press.</li>&#13;
<li>The attack exploited a previously unreported vulnerability before the affected systems or software vendor recognized and acknowledged it, reported or disclosed it, or provided warning to its customers.</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0020">Kim manages risk for an online publishing company on the island of St. Kitts, which currently uses an on-premises datacenter as its content development facility; it e-ships content to customers who are then responsible for hosting it wherever they want. Kim’s division vice president is concerned about risks, and so Kim has done some estimating. The datacenter has enough backup power supply capacity to do a graceful shutdown, but normal round-the-clock, seven-day-per-week development operations must have commercial power available. Recent experience shows that at least once per month, a brownout or blackout lasting at least eight hours occurs. Each disruption costs the company an additional two hours to restore operations. Which statements about risk assessment are not correct? (Choose all that apply.)&#13;
<ol class="upper-alpha">&#13;
<li>Risk appetite should determine the MAO, which can then be used as part of estimating SLE.</li>&#13;
<li>If the SLE exceeds the safeguard value, Kim should advise that the company implement that safeguard.</li>&#13;
<li>If the ALE exceeds the safeguard value, Kim should advise that the company implement that safeguard.</li>&#13;
<li>Once she has estimated the ALE, Kim can assess different safeguards to see how long their payback period might be so that she can advise her management regarding these alternatives.</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0021"><span epub:type="pagebreak" id="Page_126" role="doc-pagebreak" aria-label="126"/>Which of the following statements best describes security classification?&#13;
<ol class="upper-alpha">&#13;
<li>A security classification is a label attached to a storage device that contains sensitive information, and indicates the required protection and handling methods.</li>&#13;
<li>Security classification is a process that determines possible loss or impact if information of a given type suffers any kind of security compromise.</li>&#13;
<li>Security classification is a process that determines possible loss or impact if information of a given type is disclosed to an unauthorized person or entity.</li>&#13;
<li>Security classification groups together information types that have comparable loss or impacts if compromised to help optimize the choice of protection techniques.</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0022">Which of the following statements best describes security categorization?&#13;
<ol class="upper-alpha">&#13;
<li>A security categorization is a label attached to a storage device that contains sensitive information, and indicates the required protection and handling methods.</li>&#13;
<li>Security categorization groups together information types that have comparable loss or impacts if compromised, along with any compliance-required security protection requirements for that type of data.</li>&#13;
<li>Security categorization is a process that determines possible loss or impact if information of a given type is disclosed to an unauthorized person or entity.</li>&#13;
<li>Security categorization groups together information types that have comparable loss or impacts if compromised, to help optimize the choice of protection techniques.</li>&#13;
</ol>&#13;
</li>&#13;
&#13;
<li id="c03-ex-0023">Which of the following events are threats?&#13;
<ol class="upper-alpha">&#13;
<li>A thunderstorm that interrupts commercial electrical power</li>&#13;
<li>A user who copies data that they do not need for work-related tasks onto a removable storage device</li>&#13;
<li>A systems administrator who leaves their workstation logged in to their privileged account, while they take a coffee break</li>&#13;
<li>A network firewall that malfunctions, sporadically blocking some but not all traffic, due to its power supply overheating</li>&#13;
</ol>&#13;
</li>&#13;
</ol>&#13;
</section>&#13;
</section>&#13;
</section>&#13;
</div></body>
</html>